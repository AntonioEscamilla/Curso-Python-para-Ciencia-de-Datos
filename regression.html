<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Regresi√≥n con Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <style>
        :root {
            --primary-dark: #04142b;
            --primary-medium: #142a45;
            --accent-green: #00ff85;
            --text-light: #e6e8ea;
            --text-grey: #a3a8ae;
            --progress-bg: #1f3754;
            --code-bg: #1e1e1e;
            --output-border: #b07ff3;
            
            /* Colores para los recuadros informativos */
            --note-bg: #c5e0ff;
            --note-border: #0d47a1;
            --warning-bg: #ffe082;
            --warning-border: #e65100;
            --tip-bg: #b9f6ca;
            --tip-border: #1b5e20;
            --info-text: #222222;
        }
        
        body {
            font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            color: var(--text-light);
            background-color: var(--primary-dark);
        }
        
        .course-header {
            background-color: var(--primary-dark);
            padding: 1.5rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        .course-label {
            color: var(--text-grey);
            font-size: 0.9rem;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 0.5rem;
        }
        
        .course-title {
            color: var(--text-light);
            font-size: 2rem;
            font-weight: 700;
            margin: 0.5rem 0;
        }
        
        .course-author {
            color: var(--text-grey);
            font-size: 1rem;
            margin-top: 0.5rem;
        }
        
        .progress-container {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 1.5rem 0;
        }
        
        .progress-bar {
            flex-grow: 1;
            height: 6px;
            background-color: var(--progress-bg);
            border-radius: 3px;
            margin-right: 15px;
            position: relative;
        }
        
        .progress-fill {
            height: 100%;
            width: 0%;
            background-color: var(--accent-green);
            border-radius: 3px;
        }
        
        .progress-info {
            display: flex;
            align-items: center;
            color: var(--text-grey);
            font-size: 0.9rem;
        }
        
        .progress-info i {
            margin-right: 5px;
        }
        
        .btn {
            background-color: var(--accent-green);
            color: var(--primary-dark);
            border: none;
            border-radius: 6px;
            padding: 0.8rem 1.8rem;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .btn:hover {
            opacity: 0.9;
            transform: translateY(-1px);
        }
        
        .btn-practice {
            background-color: transparent;
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--text-light);
            display: flex;
            align-items: center;
            padding: 0.6rem 1.2rem;
        }
        
        .btn-practice i {
            margin-right: 8px;
            color: #ff8a00;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }
        
        nav {
            background-color: var(--primary-medium);
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
        }
        
        nav ul {
            list-style-type: none;
            margin: 0;
            padding: 0;
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
        }
        
        nav li {
            margin-bottom: 0.5rem;
        }
        
        nav a {
            color: var(--text-grey);
            text-decoration: none;
            font-weight: 500;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            transition: all 0.2s ease;
        }
        
        nav a:hover, nav a.active {
            color: var(--text-light);
            background-color: rgba(255, 255, 255, 0.1);
        }
        
        nav a.active {
            border-left: 3px solid var(--accent-green);
        }
        
        .content-section {
            background-color: var(--primary-medium);
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
        }
        
        h1, h2, h3 {
            color: var(--text-light);
            font-weight: 700;
        }
        
        h1 {
            font-size: 2.2rem;
            margin-bottom: 1.5rem;
        }
        
        h2 {
            font-size: 1.8rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
            color: var(--accent-green);
        }
        
        code {
            font-family: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
            background-color: rgba(0, 0, 0, 0.3);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            color: #e6e6e6;
        }
        
        /* Para c√≥digo dentro de los bloques de informaci√≥n con texto oscuro */
        .note code, .warning code, .tip code {
            background-color: rgba(0, 0, 0, 0.1);
            color: var(--info-text);
            font-weight: 500;
        }
        
        /* Estilos para bloques de c√≥digo */
        pre {
            background-color: var(--code-bg) !important;
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
            position: relative;
            border-left: 3px solid var(--accent-green);
            line-height: 1.5;
        }
        
        pre code,
        pre code.hljs,
        .hljs {
            background-color: var(--code-bg) !important;
            padding: 0;
            color: #d4d4d4;
        }
        
        /* Forzar que no haya ning√∫n fondo en los elementos dentro del c√≥digo */
        pre *, pre code *, pre code.hljs * {
            background-color: transparent !important;
        }
        
        /* Mantener colores de sintaxis */
        .hljs-comment {
            color: #6a9955 !important;
            background-color: transparent !important;
        }
        
        .hljs-keyword, .hljs-built_in, .hljs-literal {
            color: #ff7b72 !important;
            background-color: transparent !important;
        }
        
        .hljs-string {
            color: #ce9178 !important;
            background-color: transparent !important;
        }
        
        .hljs-number {
            color: #b5cea8 !important;
            background-color: transparent !important;
        }
        
        .hljs-function, .hljs-title.function_ {
            color: #dcdcaa !important;
            background-color: transparent !important;
        }
        
        .hljs-variable {
            color: #9cdcfe !important;
            background-color: transparent !important;
        }
        
        .output {
            background-color: #000000;
            border-left: 4px solid var(--output-border);
            padding: 1rem;
            margin: 1rem 0;
            color: #f1f1f1;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9rem;
            border-radius: 0 8px 8px 0;
            box-shadow: inset 0 0 10px rgba(0, 0, 0, 0.6);
        }
        
        /* Estilos para recuadros informativos */
        .note, .warning, .tip {
            border-radius: 6px;
            padding: 0.8rem 1.2rem;
            margin: 1.5rem 0;
            position: relative;
            font-size: 0.95rem;
            line-height: 1.5;
            border-left-width: 6px;
            border-left-style: solid;
            color: var(--info-text);
        }
        
        /* Estilo para NOTA - azul */
        .note {
            background-color: var(--note-bg);
            border-left-color: var(--note-border);
        }
        
        .note::before {
            content: "Nota:";
            font-weight: 700;
            color: var(--note-border);
            margin-right: 0.3rem;
        }
        
        /* Estilo para ADVERTENCIA - amarillo/naranja */
        .warning {
            background-color: var(--warning-bg);
            border-left-color: var(--warning-border);
        }
        
        .warning::before {
            content: "Advertencia:";
            font-weight: 700;
            color: var(--warning-border);
            margin-right: 0.3rem;
        }
        
        /* Estilo para TIP - verde */
        .tip {
            background-color: var(--tip-bg);
            border-left-color: var(--tip-border);
        }
        
        .tip::before {
            content: "Tip:";
            font-weight: 700;
            color: var(--tip-border);
            margin-right: 0.3rem;
        }
        
        .welcome-message {
            font-size: 1.1rem;
            line-height: 1.7;
            margin-bottom: 2rem;
            color: var(--text-grey);
        }
        
        .highlight {
            color: var(--accent-green);
            font-weight: 600;
        }
        
        .icon-clock:before {
            content: "‚è±Ô∏è";
            margin-right: 5px;
        }
        
        .icon-dumbbell:before {
            content: "üèãÔ∏è";
            margin-right: 5px;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding: 1rem;
            color: var(--text-grey);
            border-top: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        /* Estilos para im√°genes */
        .img-container {
            margin: 2rem 0;
            text-align: center;
        }
        
        .img-container img {
            max-width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        }
        
        .caption {
            color: var(--text-grey);
            font-size: 0.9rem;
            margin-top: 0.5rem;
            font-style: italic;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .course-title {
                font-size: 1.6rem;
            }
            
            nav ul {
                flex-direction: column;
            }
        }

        .table-container {
            margin: 2rem auto;
            max-width: 800px; /* Ancho m√°ximo para centrar */
        }

        .builtin-functions {
            width: 100%;
            border-collapse: collapse;
            background-color: var(--primary-medium);
            color: var(--text-light);
            margin: 0 auto; /* Centrar la tabla */
        }

        .builtin-functions tr:nth-child(odd) {
            background-color: var(--primary-medium); /* Primer tono de azul */
        }

        .builtin-functions tr:nth-child(even) {
            background-color: rgba(30, 60, 100, 0.6); /* Segundo tono de azul m√°s claro */
        }

        .builtin-functions td {
            padding: 10px 15px;
            text-align: left;
            border: none; /* Eliminar bordes laterales */
            border-bottom: 1px solid rgba(255, 255, 255, 0.2); /* L√≠nea horizontal blanca */
        }

        /* Doble l√≠nea en la parte superior de la primera fila */
        .builtin-functions tr:first-child td {
            border-top: 3px double rgba(255, 255, 255, 0.4);
        }

        .builtin-functions code {
            font-family: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
            color: var(--accent-green);
        }

        .builtin-functions tr:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .resources-list {
            margin: 1.5rem 0;
        }

        .resources-list li {
            margin-bottom: 1rem;
            line-height: 1.6;
        }

        .resources-list strong {
            color: var(--accent-green);
        }

        .resources-list {
            margin: 1.5rem 0;
        }
        
        .resources-list li {
            margin-bottom: 1rem;
            line-height: 1.6;
        }
        
        .resources-list strong {
            color: var(--accent-green);
        }
        
        .resources-list a {
            color: var(--accent-green) !important; /* Forzar color verde */
            text-decoration: none;
            transition: all 0.2s ease;
        }
        
        .resources-list a:hover {
            text-decoration: underline;
            opacity: 0.9; /* Ligero cambio de opacidad al pasar el cursor */
        }

        .feedback-section {
            background-color: var(--primary-medium);
            padding: 1.5rem;
            border-radius: 10px;
            margin: 2rem 0;
            text-align: center;
        }

        .feedback-section h3 {
            color: var(--text-light);
            margin-bottom: 1.2rem;
        }

        .feedback-buttons {
            display: flex;
            justify-content: center;
            gap: 1rem;
        }

        .feedback-btn {
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0.6rem 1.5rem;
            font-size: 1rem;
            border-radius: 6px;
            transition: all 0.2s ease;
            cursor: pointer;
        }

        .feedback-yes {
            background-color: rgba(0, 255, 133, 0.2);
            border: 1px solid var(--accent-green);
            color: var(--accent-green);
        }

        .feedback-no {
            background-color: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: var(--text-light);
        }

        .feedback-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }

        .feedback-icon {
            margin-right: 8px;
            font-size: 1.2rem;
        }

        .license-icons {
            display: inline-flex;
            gap: 0.5rem;
            margin-left: 1rem;
            align-items: center;
        }

        .license-link {
            display: flex;
            gap: 0.5rem;
            text-decoration: none;
        }

        .license-icon {
            width: 28px;
            height: 28px;
            transition: transform 0.2s ease;
        }

        .icon-tooltip {
            position: relative;
            cursor: pointer;
        }

        .icon-tooltip:hover .license-icon {
            transform: scale(1.1);
        }

        .icon-tooltip::after {
            content: attr(data-tooltip);
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background-color: var(--primary-dark);
            color: var(--text-light);
            padding: 0.3rem 0.6rem;
            border-radius: 4px;
            font-size: 0.8rem;
            white-space: nowrap;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.2s ease;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.3);
            z-index: 100;
        }

        .icon-tooltip:hover::after {
            opacity: 1;
        }

        .hamburger-menu {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .hamburger-button {
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            width: 40px;
            height: 35px;
            background-color: var(--primary-medium);
            border: none;
            border-radius: 5px;
            padding: 8px;
            cursor: pointer;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .bar {
            height: 3px;
            width: 100%;
            background-color: var(--accent-green);
            border-radius: 2px;
            transition: all 0.3s ease;
        }

        .menu-content {
            position: absolute;
            right: 0;
            top: 50px;
            width: 250px;
            background-color: var(--primary-medium);
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            padding: 1.5rem;
            transform: scale(0.95);
            transform-origin: top right;
            opacity: 0;
            visibility: hidden;
            transition: all 0.2s ease;
            max-height: 80vh;
            overflow-y: auto;
        }

        .menu-content h3 {
            color: var(--accent-green);
            margin-top: 0;
            margin-bottom: 1rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            padding-bottom: 0.5rem;
        }

        .menu-content ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .menu-content li {
            margin-bottom: 0.7rem;
        }

        .menu-content a {
            color: var(--text-light);
            text-decoration: none;
            display: block;
            padding: 0.5rem;
            border-radius: 4px;
            transition: all 0.2s ease;
        }

        .menu-content a:hover {
            background-color: rgba(255, 255, 255, 0.1);
            color: var(--accent-green);
        }

        /* Clase para mostrar/ocultar el men√∫ */
        .hamburger-menu.active .menu-content {
            transform: scale(1);
            opacity: 1;
            visibility: visible;
        }

        /* Animaci√≥n de las barras cuando est√° activo */
        .hamburger-menu.active .bar:nth-child(1) {
            transform: translateY(10px) rotate(45deg);
        }

        .hamburger-menu.active .bar:nth-child(2) {
            opacity: 0;
        }

        .hamburger-menu.active .bar:nth-child(3) {
            transform: translateY(-10px) rotate(-45deg);
        }

        /* Estilos para navegaci√≥n entre cap√≠tulos */
        .chapter-navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 2rem;
            padding-top: 1.5rem;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }

        .nav-btn {
            display: inline-flex;
            align-items: center;
            padding: 0.8rem 1.5rem;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.2s ease;
            background-color: var(--primary-medium);
            color: var(--text-light);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .nav-btn:hover {
            background-color: var(--accent-green);
            color: var(--primary-dark);
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }

        .nav-icon {
            font-size: 0.9rem;
            margin: 0 0.5rem;
        }

        .nav-prev .nav-icon {
            margin-right: 0.5rem;
            margin-left: 0;
        }

        .nav-next .nav-icon {
            margin-left: 0.5rem;
            margin-right: 0;
        }

        /* Para p√°ginas con un solo bot√≥n de navegaci√≥n (como la primera) */
        .chapter-navigation.single-button {
            justify-content: flex-end; /* Alinea el contenido al extremo derecho */
        }

        /* En pantallas peque√±as, ajustar la navegaci√≥n para mejor visualizaci√≥n */
        @media (max-width: 768px) {
            .chapter-navigation {
                flex-direction: column;
                gap: 1rem;
            }

            .nav-btn {
                text-align: center;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="hamburger-menu">
        <button class="hamburger-button" aria-label="Abrir men√∫ de navegaci√≥n">
            <span class="bar"></span>
            <span class="bar"></span>
            <span class="bar"></span>
        </button>
        
        <div class="menu-content">
            <h3>Secciones</h3>
            <ul>
                <li><a href="#intro-regresion">Introducci√≥n a la Regresi√≥n</a></li>
                <li><a href="#regresion-lineal">Regresi√≥n Lineal</a></li>
                <li><a href="#regresion-polinomial">Regresi√≥n Polinomial</a></li>
                <li><a href="#regularizacion">T√©cnicas de Regularizaci√≥n</a></li>
                <li><a href="#evaluacion-modelos">Evaluaci√≥n de Modelos</a></li>
                <li><a href="#material-practica">Material de Pr√°ctica</a></li>
                <li><a href="#referencias">Referencias</a></li>
            </ul>
        </div>
     </div>
     
     <div class="course-header">
        <div class="container">
            <div class="course-label">CURSO</div>
            <h1 class="course-title">Python para Ciencia de Datos</h1>
            <div class="course-author">Ph.D. Antonio Escamilla P.</div>
            
            <div class="progress-container">
                <div class="progress-bar">
                    <div class="progress-fill" style="width: 75%;"></div>
                </div>
                <div class="progress-info">
                    <span class="icon-clock"></span>
                    3 sections to go
                </div>
            </div>
            
            <div style="display: flex; justify-content: space-between;">
                <button class="btn btn-practice" onclick="document.getElementById('material-practica').scrollIntoView({behavior: 'smooth'})">
                    <span class="icon-dumbbell"></span>
                    Practica
                </button>
                <button class="btn" onclick="window.location.href='classification.html'">Continuar</button>
            </div>
        </div>
     </div>
     
     <div class="container">
        <nav>
            <ul>
                <li><a href="index.html">1. Introducci√≥n a Python</a></li>
                <li><a href="numpy.html">2. NumPy</a></li>
                <li><a href="pandas.html">3. Pandas</a></li>
                <li><a href="polars.html">4. Polars</a></li>
                <li><a href="visualization.html">5. Visualizaci√≥n</a></li>
                <li><a href="machine_learning.html">6. Machine Learning</a></li>
                <li><a href="regression.html" class="active">7. Regresi√≥n</a></li>
                <li><a href="classification.html">8. Clasificaci√≥n</a></li>
                <li><a href="clustering.html">9. Clustering</a></li>
            </ul>
        </nav>
        
        <div class="content-section">
            <h1 id="intro-regresion">Cap√≠tulo 7: Modelos de Regresi√≥n en Machine Learning</h1>
            
            <h2 id="que-es-regresion">¬øQu√© es la Regresi√≥n?</h2>
            
            <p>La regresi√≥n es una t√©cnica de aprendizaje supervisado que permite predecir valores num√©ricos continuos a partir de datos. A diferencia de la clasificaci√≥n que asigna categor√≠as, la regresi√≥n estima magnitudes espec√≠ficas como precios, temperaturas, edades o cualquier variable cuantitativa.</p>
            
            <div class="img-container">
                <img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_ols_001.png" alt="Ejemplo de regresi√≥n lineal">
                <div class="caption">Regresi√≥n lineal simple mostrando la relaci√≥n entre variables (Fuente: Scikit-learn)</div>
            </div>
            
            <p>Los modelos de regresi√≥n son fundamentales en ciencia de datos y se utilizan ampliamente para:</p>
            
            <ul>
                <li><strong>Predicci√≥n de precios</strong>: inmuebles, acciones, productos, etc.</li>
                <li><strong>Pron√≥stico de ventas</strong> y an√°lisis de tendencias temporales</li>
                <li><strong>Estimaci√≥n de riesgos</strong> en seguros y finanzas</li>
                <li><strong>An√°lisis de relaciones</strong> entre variables en investigaci√≥n cient√≠fica</li>
                <li><strong>Optimizaci√≥n de procesos</strong> industriales y log√≠sticos</li>
            </ul>
            
            <h2 id="tipos-regresion">Tipos de Modelos de Regresi√≥n</h2>
            <p>En este cap√≠tulo exploraremos varios tipos de modelos de regresi√≥n, cada uno con sus propias caracter√≠sticas y casos de uso:</p>
        </div>

        <div class="content-section">
            <h2 id="flujo-regresion">Flujo de Trabajo para Problemas de Regresi√≥n</h2>

            <p>Implementar un modelo de regresi√≥n efectivo requiere seguir un proceso estructurado que va desde la exploraci√≥n de datos hasta la interpretaci√≥n y despliegue del modelo. En esta secci√≥n, desarrollaremos un flujo de trabajo completo para problemas de regresi√≥n siguiendo estas etapas fundamentales:</p>

            <ol>
                <li><strong>Exploraci√≥n y an√°lisis de datos</strong>: Entender la estructura, distribuci√≥n y relaciones en nuestros datos</li>
                <li><strong>Preparaci√≥n de datos</strong>: Limpieza, manejo de valores faltantes y transformaci√≥n</li>
                <li><strong>Ingenier√≠a de caracter√≠sticas</strong>: Crear, seleccionar y procesar variables predictoras</li>
                <li><strong>Selecci√≥n y entrenamiento de modelos</strong>: Evaluar diferentes algoritmos de regresi√≥n</li>
                <li><strong>Optimizaci√≥n de hiperpar√°metros</strong>: Afinar los modelos para mejor rendimiento</li>
                <li><strong>Evaluaci√≥n e interpretaci√≥n</strong>: Medir la calidad predictiva y entender el modelo</li>
                <li><strong>Implementaci√≥n y monitoreo</strong>: Desplegar el modelo para su uso</li>
            </ol>

            <p>Utilizaremos un conjunto de datos de autom√≥viles para predecir precios en base a diversas caracter√≠sticas, aplicando las t√©cnicas m√°s relevantes de regresi√≥n con scikit-learn y otras herramientas de Python para ciencia de datos.</p>

            <div class="note">
                Este flujo de trabajo es aplicable a pr√°cticamente cualquier problema de regresi√≥n, con adaptaciones espec√≠ficas seg√∫n la naturaleza de los datos y el contexto del problema.
            </div>
        </div>

        <div class="content-section">
    <h2 id="introduccion-carga-datos">Etapa 1: Introducci√≥n y Carga de Datos</h2>
    
    <p>Utilizaremos un dataset de autom√≥viles que contiene informaci√≥n sobre caracter√≠sticas t√©cnicas y precios. Nuestro objetivo ser√° construir un modelo que prediga el precio de un autom√≥vil basado en sus caracter√≠sticas.</p>
    
    <h3>Importaci√≥n de librer√≠as b√°sicas</h3>
    
    <p>Primero importamos las bibliotecas principales para an√°lisis de datos y visualizaci√≥n:</p>
    
    <pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

print(pd.__version__)</code></pre>

    <pre class="output"><code class="language-shell">2.2.2</code></pre>

    <h3>Informaci√≥n del dataset</h3>
    
    <p>El conjunto de datos que utilizaremos contiene tres tipos de caracter√≠sticas:</p>
    <ul>
        <li>Especificaciones t√©cnicas del autom√≥vil (como dimensiones, peso, potencia, etc.)</li>
        <li>Calificaci√≥n de riesgo de seguro asignada</li>
        <li>P√©rdidas normalizadas en comparaci√≥n con otros autom√≥viles</li>
    </ul>
    
    <p>Los valores faltantes est√°n identificados con un "?" en el dataset original.</p>
    
    <pre><code class="language-python"># Definici√≥n de las columnas del dataset
columnas = ['symboling', 'normalized-losses', 'make',
           'fuel-type', 'aspiration', 'num-of-doors',
           'body-style', 'drive-wheels', 'engine-location',
           'wheel-base', 'length', 'width', 'height',
           'curb-weight', 'engine-type', 'num-of-cylinders',
           'engine-size', 'fuel-system', 'bore', 'stroke',
           'compression-ratio', 'horsepower', 'peak-rpm',
           'city-mpg', 'highway-mpg', 'price']

# URL de los datos
url_data = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto_imports.csv'

# Carga de datos con manejo de valores faltantes
auto_df = pd.read_csv(url_data,
                      header=None,
                      names=columnas,
                      na_values='?')

# Ver 5 registros aleatorios
auto_df.sample(5)</code></pre>
    
    <div class="img-container">
        <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/tabla%201.png" alt="Muestra de registros del dataset de autom√≥viles">
        <div class="caption">Muestra aleatoria de 5 registros del dataset de autom√≥viles</div>
    </div>
    
    <pre><code class="language-python"># Tama√±o del dataset
print(f'El tama√±o del conjunto de datos es {auto_df.shape} \n')

# Informaci√≥n del dataset
auto_df.info()</code></pre>
    
    <pre class="output"><code class="language-shell">El tama√±o del conjunto de datos es (205, 26) 

&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 205 entries, 0 to 204
Data columns (total 26 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   symboling          205 non-null    int64  
 1   normalized-losses  164 non-null    float64
 2   make               205 non-null    object 
 3   fuel-type          205 non-null    object 
 4   aspiration         205 non-null    object 
 5   num-of-doors       203 non-null    object 
 6   body-style         205 non-null    object 
 7   drive-wheels       205 non-null    object 
 8   engine-location    205 non-null    object 
 9   wheel-base         205 non-null    float64
 10  length             205 non-null    float64
 11  width              205 non-null    float64
 12  height             205 non-null    float64
 13  curb-weight        205 non-null    int64  
 14  engine-type        205 non-null    object 
 15  num-of-cylinders   205 non-null    object 
 16  engine-size        205 non-null    int64  
 17  fuel-system        205 non-null    object 
 18  bore               201 non-null    float64
 19  stroke             201 non-null    float64
 20  compression-ratio  205 non-null    float64
 21  horsepower         203 non-null    float64
 22  peak-rpm           203 non-null    float64
 23  city-mpg           205 non-null    int64  
 24  highway-mpg        205 non-null    int64  
 25  price              201 non-null    float64
dtypes: float64(11), int64(5), object(10)
memory usage: 41.8+ KB</code></pre>
    
    <div class="tip">
        Observamos que algunas columnas tienen valores faltantes. Es importante identificar estos valores y planificar una estrategia para manejarlos durante la fase de preprocesamiento.
    </div>
</div>

        <div class="content-section">
    <h2 id="preparacion-datos">Etapa 2: Preparaci√≥n de Datos</h2>
    
    <h3>An√°lisis de datos faltantes</h3>
    
    <p>Es fundamental identificar los valores faltantes en nuestro dataset para decidir la mejor estrategia de manejo. Durante la carga, reemplazamos los s√≠mbolos "?" con NaN para facilitar su detecci√≥n:</p>
    
    <pre><code class="language-python"># Verificaci√≥n de valores faltantes por columna
auto_df.isna().sum()</code></pre>
    
    <pre class="output"><code class="language-shell">symboling            0
normalized-losses   41
make                 0
fuel-type            0
aspiration           0
num-of-doors         2
body-style           0
drive-wheels         0
engine-location      0
wheel-base           0
length               0
width                0
height               0
curb-weight          0
engine-type          0
num-of-cylinders     0
engine-size          0
fuel-system          0
bore                 4
stroke               4
compression-ratio    0
horsepower           2
peak-rpm             2
city-mpg             0
highway-mpg          0
price                4
dtype: int64</code></pre>
    
    <p>Podemos ver que algunas columnas tienen valores faltantes, siendo "normalized-losses" la que m√°s presenta (41 valores). Durante el feature engineering, implementaremos estrategias para manejar estos valores.</p>
    
    <h3>Conversi√≥n de variables a su formato correcto</h3>
    
    <p>Vamos a convertir las variables categ√≥ricas al tipo de dato adecuado, distinguiendo entre categ√≥ricas nominales y ordinales:</p>
    
    <pre><code class="language-python"># Corregir las variables categ√≥ricas
cols_categoricas = ["make", "fuel-type", "aspiration", "num-of-doors",
                    "body-style", "drive-wheels", "engine-location",
                    "engine-type", "num-of-cylinders", "fuel-system"]

auto_df[cols_categoricas] = auto_df[cols_categoricas].astype("category")

# Corregir variables categ√≥ricas ordinales
auto_df["num-of-doors"] = pd.Categorical(auto_df["num-of-doors"],
                                         categories=["two","four"],
                                         ordered=True)

auto_df["num-of-cylinders"] = pd.Categorical(auto_df["num-of-cylinders"],
                                             categories=["two", "three", "four",
                                                         "five", "six", "eight",
                                                         "twelve"],
                                             ordered=True)

# Verificamos la informaci√≥n del dataset despu√©s de las conversiones
auto_df.info()</code></pre>
    
    <pre class="output"><code class="language-shell">&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 205 entries, 0 to 204
Data columns (total 26 columns):
 #   Column             Non-Null Count  Dtype   
---  ------             --------------  -----   
 0   symboling          205 non-null    int64   
 1   normalized-losses  164 non-null    float64 
 2   make               205 non-null    category
 3   fuel-type          205 non-null    category
 4   aspiration         205 non-null    category
 5   num-of-doors       203 non-null    category
 6   body-style         205 non-null    category
 7   drive-wheels       205 non-null    category
 8   engine-location    205 non-null    category
 9   wheel-base         205 non-null    float64 
 10  length             205 non-null    float64 
 11  width              205 non-null    float64 
 12  height             205 non-null    float64 
 13  curb-weight        205 non-null    int64   
 14  engine-type        205 non-null    category
 15  num-of-cylinders   205 non-null    category
 16  engine-size        205 non-null    int64   
 17  fuel-system        205 non-null    category
 18  bore               201 non-null    float64 
 19  stroke             201 non-null    float64 
 20  compression-ratio  205 non-null    float64 
 21  horsepower         203 non-null    float64 
 22  peak-rpm           203 non-null    float64 
 23  city-mpg           205 non-null    int64   
 24  highway-mpg        205 non-null    int64   
 25  price              201 non-null    float64 
dtypes: category(10), float64(11), int64(5)
memory usage: 28.6 KB</code></pre>
    
    <p>Ahora obtenemos algunos estad√≠sticos descriptivos b√°sicos del conjunto de datos:</p>
    
    <pre><code class="language-python"># Descripci√≥n estad√≠stica de las variables num√©ricas
auto_df.describe()</code></pre>
    
    <div class="img-container">
        <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/tabla%202.png" alt="Estad√≠sticos descriptivos del dataset">
        <div class="caption">Estad√≠sticos descriptivos de las variables num√©ricas del dataset</div>
    </div>
    
    <p>Las estad√≠sticas descriptivas nos dan una idea de las distribuciones y rangos de nuestras variables num√©ricas. Por ejemplo, vemos que el precio (nuestra variable objetivo) var√≠a desde 5,118 hasta 45,400 d√≥lares, con un promedio de 13,207 d√≥lares.</p>
    
    <div class="warning">
        El an√°lisis descriptivo es clave para detectar posibles problemas con los datos antes de entrenar un modelo. Por ejemplo, rangos extremadamente amplios pueden indicar outliers, y variables altamente sesgadas podr√≠an requerir transformaciones.
    </div>
</div>

        <div class="content-section">
            <h2 id="analisis-univariable-bivariable">Etapa 3: An√°lisis Univariable y Bivariable</h2>
            
            <h3>An√°lisis de variables categ√≥ricas</h3>
            
            <p>En el an√°lisis univariable examinamos cada variable individualmente para entender su distribuci√≥n y detectar posibles problemas. Para las variables categ√≥ricas, verificamos su frecuencia:</p>
            
<pre><code class="language-python">cols_cate_problemas = ["make", "fuel-system", "num-of-cylinders"]

for col in cols_cate_problemas:
    print(auto_df[col].value_counts())
    print("")</code></pre>
            
<pre class="output"><code class="language-shell">make
toyota         32
nissan         18
mazda          17
honda          13
mitsubishi     13
subaru         12
volkswagen     12
peugot         11
volvo          11
audi           10
bmw             8
dodge           8
mercedes-benz   8
plymouth        7
saab            6
porsche         5
jaguar          3
chevrolet       3
alfa-romeo      3
isuzu           3
mercury         1
renault         1
Name: count, dtype: int64

fuel-system
mpfi    94
2bbl    66
idi     20
1bbl    11
spdi     3
4bbl     3
mfi      1
spfi     1
Name: count, dtype: int64

num-of-cylinders
four     94
six      40
five     11
eight     5
two       4
three     1
twelve    1
Name: count, dtype: int64</code></pre>
            
            <h3>Problemas identificados en variables categ√≥ricas</h3>
            
            <p>Algunos valores categ√≥ricos solo est√°n presentes en un solo registro, lo que podr√≠a causar problemas en los encoders:</p>
            <ul>
                <li>make = mercury o renault</li>
                <li>fuel-system = mfi o spfi</li>
                <li>num-of-cylinders = three o twelve</li>
            </ul>
            
            <p>Este desequilibrio tendr√° que ser considerado durante el feature engineering para evitar problemas de generalizaci√≥n.</p>
            
            <h3>Scatter Plots para variables num√©ricas vs precio</h3>
            
            <p>Ahora analizamos la relaci√≥n entre las variables num√©ricas y nuestra variable objetivo (precio):</p>
            
<pre><code class="language-python"># Listado de variables num√©ricas excepto price
cols_numericas = (auto_df
                  .drop(columns=["price"])
                  .select_dtypes(include=np.number)
                  .columns.tolist())
print(cols_numericas)
print(len(cols_numericas))</code></pre>
            
<pre class="output"><code class="language-shell">['symboling', 'normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']
15</code></pre>
            
<pre><code class="language-python"># Crear scatter plots: 5 filas y 3 columnas
fig, axes = plt.subplots(5, 3, figsize=(15, 15))
axes = axes.flatten()

for i, col in enumerate(cols_numericas):
    sns.regplot(data=auto_df,
                x=col, y="price",
                ax=axes[i])
    axes[i].set_title(col)

plt.tight_layout()
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%201.png" alt="Scatter plots de variables num√©ricas vs precio" width="70%">
                <div class="caption">Scatter plots que muestran la relaci√≥n entre cada variable num√©rica y el precio</div>
            </div>
            
            <p>Estos gr√°ficos nos permiten identificar visualmente relaciones entre las variables predictoras y el precio. Por ejemplo, podemos observar correlaciones positivas fuertes entre el precio y variables como 'engine-size', 'curb-weight' y 'width', mientras que hay correlaciones negativas con 'city-mpg' y 'highway-mpg'.</p>
            
            <h3>Correlaci√≥n entre variables num√©ricas</h3>
            
<pre><code class="language-python"># Matriz de correlaci√≥n
automobile_corr = auto_df.corr(numeric_only=True)
fig, ax = plt.subplots(figsize=(12, 10))
sns.heatmap(automobile_corr, annot=True, fmt=".2f");</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%202.png" alt="Matriz de correlaci√≥n" width="70%">
                <div class="caption">Matriz de correlaci√≥n de las variables num√©ricas</div>
            </div>
            
            <p>La matriz de correlaci√≥n confirma nuestras observaciones de los scatter plots y proporciona una medida cuantitativa de la fuerza de cada relaci√≥n. Por ejemplo:</p>
            <ul>
                <li>Las variables 'engine-size' y 'price' tienen una correlaci√≥n de aproximadamente 0.87, indicando una fuerte relaci√≥n lineal positiva.</li>
                <li>Las variables 'city-mpg' y 'price' tienen una correlaci√≥n de aproximadamente -0.69, se√±alando una relaci√≥n lineal negativa moderada a fuerte.</li>
            </ul>
            
            <div class="note">
                Tambi√©n observamos correlaciones fuertes entre predictores (como entre 'length' y 'curb-weight'), lo que podr√≠a indicar multicolinealidad. Esta informaci√≥n ser√° importante al seleccionar modelos, ya que algunos son m√°s susceptibles a problemas de multicolinealidad que otros.
            </div>
            
            <h3>Visualizaci√≥n de variables categ√≥ricas vs precio</h3>
            
<pre><code class="language-python"># Boxplots para variables categ√≥ricas vs precio
fig, axes = plt.subplots(5, 2, figsize=(15, 15))
axes = axes.flatten()

for i, col in enumerate(cols_categoricas):
    sns.boxplot(data=auto_df,
                x="price", y=col,
                ax=axes[i])
    axes[i].set_title(col)

plt.tight_layout()
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%203.png" alt="Boxplots de variables categ√≥ricas vs precio" width="70%">
                <div class="caption">Boxplots que muestran la distribuci√≥n de precios por categor√≠a para cada variable categ√≥rica</div>
            </div>
            
            <p>Hay variables categ√≥ricas que permiten distinguir claramente entre grupos de valores de precio. Por ejemplo:</p>
            <ul>
                <li>La variable 'engine-location' muestra una diferencia significativa en los precios entre los dos grupos ("front" y "rear"), lo que sugiere que es una variable informativa.</li>
                <li>Por el contrario, la variable 'num-of-doors' no muestra una distinci√≥n clara en los precios, lo que indica que podr√≠a ser menos relevante para la predicci√≥n.</li>
            </ul>
            
            <div class="tip">
                Para medir formalmente la relaci√≥n entre variables categ√≥ricas y una variable num√©rica como el precio, podr√≠amos utilizar la prueba ANOVA (Analysis of Variance). Esta prueba nos dir√≠a si las diferencias entre los grupos son estad√≠sticamente significativas.
            </div>
        </div>

        <div class="content-section">
            <h2 id="feature-engineering">Etapa 4: Feature Engineering</h2>
            
            <p>El feature engineering es fundamental para preparar nuestros datos para el modelado. En este caso, implementaremos estrategias para manejar valores faltantes y transformar variables categ√≥ricas.</p>
            
            <h3>Definici√≥n de pipelines de transformaci√≥n</h3>
            
            <p>Utilizaremos scikit-learn para crear pipelines de preprocesamiento que aplicar√°n diferentes transformaciones seg√∫n el tipo de variable:</p>
            
<pre><code class="language-python"># Librer√≠as para el preprocesamiento de datos
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

# Definici√≥n de columnas por tipo
cols_numericas = ['symboling','normalized-losses',
                 'wheel-base','length', 'width',
                 'height', 'curb-weight',
                 'engine-size', 'bore', 'stroke',
                 'compression-ratio', 'horsepower',
                 'peak-rpm','city-mpg',
                 'highway-mpg']

cols_categoricas = ["make", "fuel-type", "aspiration",
                   "body-style", "drive-wheels",
                   "engine-location", "engine-type",
                   "fuel-system"]

cols_categoricas_ord = ["num-of-doors", "num-of-cylinders"]</code></pre>
            
            <p>A continuaci√≥n, definimos tres pipelines diferentes:</p>
            
<pre><code class="language-python"># Creaci√≥n de pipelines de transformaci√≥n
# OneHotEncoder para variables categ√≥ricas nominales
# OrdinalEncoder para variables categ√≥ricas ordinales

numeric_pipe = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median'))])

categorical_pipe = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

categorical_ord_pipe = Pipeline(steps=[
    ('ordenc', OrdinalEncoder(handle_unknown='use_encoded_value',
                             unknown_value=np.nan)),
    ('imputer', SimpleImputer(strategy='most_frequent'))])

# Combinaci√≥n de pipelines en un ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('numericas', numeric_pipe, cols_numericas),
        ('categoricas', categorical_pipe, cols_categoricas),
        ('categoricas ordinales', categorical_ord_pipe, cols_categoricas_ord)
    ])

preprocessor</code></pre>
            
<pre class="output"><code class="language-shell">ColumnTransformer(
    transformers=[('numericas',
                   Pipeline(steps=[('imputer',
                                    SimpleImputer(strategy='median'))]),
                   ['symboling', 'normalized-losses', 'wheel-base', 'length',
                    'width', 'height', 'curb-weight', 'engine-size', 'bore',
                    'stroke', 'compression-ratio', 'horsepower', 'peak-rpm',
                    'city-mpg', 'highway-mpg']),
                  ('categoricas',
                   Pipeline(steps=[('imputer',
                                    SimpleImputer(strategy='most_frequent')),
                                   ('onehot',
                                    OneHotEncoder(handle_unknown='ignore'))]),
                   ['make', 'fuel-type', 'aspiration', 'body-style',
                    'drive-wheels', 'engine-location', 'engine-type',
                    'fuel-system']),
                  ('categoricas ordinales',
                   Pipeline(steps=[('ordenc',
                                    OrdinalEncoder(handle_unknown='use_encoded_value',
                                                   unknown_value=nan)),
                                   ('imputer',
                                    SimpleImputer(strategy='most_frequent'))]),
                   ['num-of-doors', 'num-of-cylinders'])])</code></pre>
            
            <p>Este enfoque nos proporciona varias ventajas:</p>
            
            <ul>
                <li><strong>Manejo consistente de datos faltantes</strong>: Usamos la mediana para variables num√©ricas y el valor m√°s frecuente para categ√≥ricas.</li>
                <li><strong>Codificaci√≥n apropiada</strong>: OneHotEncoder para variables categ√≥ricas nominales y OrdinalEncoder para variables ordinales.</li>
                <li><strong>Robustez a valores desconocidos</strong>: Configuramos los encoders para manejar valores no vistos durante el entrenamiento.</li>
                <li><strong>Reproducibilidad</strong>: El pipeline garantiza que las mismas transformaciones se apliquen a los datos de entrenamiento y prueba.</li>
            </ul>
            
            <div class="note">
                Trabajar con pipelines mejora significativamente la reproducibilidad y evita el data leakage, que ocurre cuando informaci√≥n del conjunto de prueba influye en el preprocesamiento. Adem√°s, facilita la aplicaci√≥n de las mismas transformaciones a nuevos datos durante la fase de predicci√≥n.
            </div>
        </div>

        <div class="content-section">
            <h2 id="modelos-regresion">Etapa 5: Modelos de Regresi√≥n</h2>
            
            <p>En esta etapa, implementaremos y evaluaremos diversos modelos de regresi√≥n para predecir el precio de los autom√≥viles. Comenzaremos dividiendo nuestros datos en conjuntos de entrenamiento y prueba, y luego probaremos diferentes algoritmos para identificar el m√°s efectivo.</p>
            
            <h3>Metodolog√≠a de selecci√≥n de modelos</h3>
            
            <p>Para una selecci√≥n eficiente de modelos, seguiremos esta metodolog√≠a:</p>
            
            <ol>
                <li>Dividir los datos en conjuntos de entrenamiento (80%) y prueba (20%)</li>
                <li>Evaluar m√∫ltiples modelos inicialmente para obtener un baseline</li>
                <li>Seleccionar los modelos con mejor rendimiento para optimizaci√≥n posterior</li>
                <li>Realizar validaci√≥n cruzada para estimar el desempe√±o generalizado</li>
                <li>Optimizar hiperpar√°metros para los modelos m√°s prometedores</li>
                <li>Seleccionar el modelo final basado en desempe√±o y estabilidad</li>
            </ol>
            
            <h3>Divisi√≥n del dataset</h3>
            
<pre><code class="language-python">from sklearn.model_selection import train_test_split

X_features = auto_df.drop('price', axis='columns')
y_target = auto_df['price']

X_train, X_test, y_train, y_test = train_test_split(X_features,
                                                    y_target,
                                                    test_size=0.2,
                                                    random_state=42)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)</code></pre>
            
<pre class="output"><code class="language-shell">(160, 25) (160,)
(41, 25) (41,)</code></pre>
            
            <h3>Implementaci√≥n de funciones de evaluaci√≥n</h3>
            
            <p>Definimos funciones para entrenar y evaluar modelos de forma consistente:</p>
            
<pre><code class="language-python">from sklearn.metrics import mean_absolute_error
from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Lasso
from sklearn.linear_model import Ridge
from sklearn.linear_model import ElasticNet
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
import warnings

warnings.filterwarnings("ignore")

# Diccionario para almacenar resultados
result_dict = {}

# Funciones de ayuda para entrenar y evaluar modelos
def entrenar_modelo(modelo,
                   preprocessor,
                   x_data,
                   y_data,
                   test_frac=0.2,
                   ):
    """
    Funci√≥n para entrenar y evaluar un modelo
    Args:
        modelo: modelo de ML
        preprocessor: preprocesador de datos
        x_data: datos de entrada
        y_data: datos de salida
        test_frac: fracci√≥n de datos para el conjunto de prueba
    Returns:
        dict: diccionario con los puntajes de entrenamiento y prueba
    """
    # Dividir el dataset en entrenamiento y prueba
    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data,
                                                       random_state=42,
                                                       test_size=test_frac)

    # Crear el pipeline con el preprocesador y el modelo
    regressor_pipe = Pipeline(steps=[("preprocessor", preprocessor),
                                    ("model", modelo)])

    # Entrenar el pipeline de regresi√≥n
    model = regressor_pipe.fit(x_train, y_train)
    y_pred_train = model.predict(x_train)

    # Predecir con el pipeline de regresi√≥n
    y_pred = model.predict(x_test)

    train_score = mean_absolute_error(y_train, y_pred_train)
    test_score = mean_absolute_error(y_test, y_pred)

    print(f"Entrenamiento_score : {train_score}")
    print(f"Prueba_score : {test_score}")

    return {
        'Entrenamiento_score': train_score,
        'Prueba_score': test_score
    }

# Funci√≥n para comparar los resultados de los modelos
def compare_results():
    for key in result_dict:
        print('Regresi√≥n: ', key)
        print('Entrenamiento score', result_dict[key]['Entrenamiento_score'])
        print('Prueba score', result_dict[key]['Prueba_score'])
        print()</code></pre>
            
            <h3>Evaluaci√≥n de modelos</h3>
            
            <p>Ahora implementaremos y evaluaremos varios modelos de regresi√≥n, comenzando con un modelo base simple:</p>
            
<pre><code class="language-python"># Modelo Dummy (l√≠nea base)
result_dict['Dummy Regressor'] = entrenar_modelo(DummyRegressor(strategy='median'), preprocessor, X_train, y_train)</code></pre>
            
<pre class="output"><code class="language-shell">Entrenamiento_score : 4968.09375
Prueba_score : 5037.7439024390245</code></pre>
            
<pre><code class="language-python"># Regresi√≥n lineal
result_dict['Linear Regressor'] = entrenar_modelo(LinearRegression(), preprocessor, X_train, y_train)</code></pre>
            
<pre class="output"><code class="language-shell">Entrenamiento_score : 876.91871739725
Prueba_score : 2140.5372525530713</code></pre>
            
<pre><code class="language-python"># ElasticNet
result_dict['Elasticnet'] = entrenar_modelo(ElasticNet(alpha=1, l1_ratio=0.5, max_iter=100000, warm_start=True),
                                            preprocessor,
                                            X_train,
                                            y_train)</code></pre>
            
<pre class="output"><code class="language-shell">Entrenamiento_score : 1823.047871927852
Prueba_score : 2310.247878703888</code></pre>
            
<pre><code class="language-python"># SVR (Support Vector Regression)
result_dict['SVR'] = entrenar_modelo(SVR(kernel='linear', epsilon=0.05, C=0.3),
                                     preprocessor,
                                     X_train,
                                     y_train)</code></pre>
            
<pre class="output"><code class="language-shell">Entrenamiento_score : 1973.1475811870937
Prueba_score : 2428.6209834285455</code></pre>
            
<pre><code class="language-python"># KNN (K-Nearest Neighbors)
result_dict['KNN'] = entrenar_modelo(KNeighborsRegressor(n_neighbors=10),
                                     preprocessor,
                                     X_train,
                                     y_train)</code></pre>
            
<pre class="output"><code class="language-shell">Entrenamiento_score : 2319.37421875
Prueba_score : 2659.3841463414633</code></pre>
            
<pre><code class="language-python"># Decision Tree
result_dict['Decision Tree'] = entrenar_modelo(DecisionTreeRegressor(max_depth=2),
                                              preprocessor,
                                              X_train,
                                              y_train)</code></pre>
            
<pre class="output"><code class="language-shell">Entrenamiento_score : 2095.9670005416547
Prueba_score : 2509.0853658536585</code></pre>
            
<pre><code class="language-python"># Comparar todos los resultados
compare_results()</code></pre>
            
<pre class="output"><code class="language-shell">Regresi√≥n:  Dummy Regressor
Entrenamiento score 4968.09375
Prueba score 5037.7439024390245

Regresi√≥n:  Linear Regressor
Entrenamiento score 876.91871739725
Prueba score 2140.5372525530713

Regresi√≥n:  Elasticnet
Entrenamiento score 1823.047871927852
Prueba score 2310.247878703888

Regresi√≥n:  SVR
Entrenamiento score 1973.1475811870937
Prueba score 2428.6209834285455

Regresi√≥n:  KNN
Entrenamiento score 2319.37421875
Prueba score 2659.3841463414633

Regresi√≥n:  Decision Tree
Entrenamiento score 2095.9670005416547
Prueba score 2509.0853658536585</code></pre>
            
            <h3>Visualizaci√≥n comparativa de modelos</h3>
            
<pre><code class="language-python"># Visualizaci√≥n comparativa de resultados
# Crear un diccionario solo con los resultados de prueba de cada modelo
nombre_modelos = result_dict.keys()
resultados_train = {}  # crear diccionario vac√≠o
resultados_test = {}   # crear diccionario vac√≠o

for nombre in nombre_modelos:
    resultados_train[nombre] = result_dict[nombre]['Entrenamiento_score']
    resultados_test[nombre] = result_dict[nombre]['Prueba_score']

df_comparacion = pd.DataFrame([resultados_train, resultados_test],
                             index=['train', 'test'])

# Plot the bar chart
fig, ax = plt.subplots(figsize=(10, 4))
df_comparacion.T.plot(kind='bar', ax=ax)

# Adjust the layout
ax.set_ylabel('MAE score')
ax.set_title('Comparaci√≥n de Modelos [MAE] ')

# Set the x-tick labels inside the bars and rotate by 90 degrees
ax.set_xticks(range(len(df_comparacion.columns)))
ax.set_xticklabels([])

# Draw the x-tick labels inside the bars rotated by 45 degrees
for i, label in enumerate(df_comparacion.columns):
    bar_center = (df_comparacion.loc['train', label] +
                 df_comparacion.loc['test', label]) / 2
    ax.text(i, bar_center, label, ha='center',
           va='center_baseline', rotation=45)

# Plotear l√≠nea en el resultado de DummyRegressor
ax.axhline(df_comparacion['Dummy Regressor']['test'],
          color='red',
          linestyle='--',
          alpha=0.8)

plt.tight_layout()
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%204.png" alt="Comparaci√≥n de modelos de regresi√≥n">
                <div class="caption">Comparaci√≥n de error (MAE) en entrenamiento y prueba para diferentes modelos</div>
            </div>
            
            <div class="note">
                Bas√°ndonos en los resultados, observamos que:
                <ul>
                    <li>Todos los modelos superan significativamente al modelo base (Dummy Regressor).</li>
                    <li>La regresi√≥n lineal tiene el mejor rendimiento en el conjunto de entrenamiento, pero muestra una diferencia considerable entre entrenamiento y prueba, lo que podr√≠a indicar sobreajuste.</li>
                    <li>ElasticNet muestra un buen balance entre rendimiento en entrenamiento y prueba, sugiriendo mejor generalizaci√≥n.</li>
                    <li>Los modelos con m√°s par√°metros (como la regresi√≥n lineal completa) presentan mayor diferencia entre rendimiento de entrenamiento y prueba, indicando posible sobreajuste.</li>
                </ul>
            </div>
            
            <div class="warning">
                Una diferencia grande entre el rendimiento en entrenamiento y prueba (como vemos en el modelo de regresi√≥n lineal) indica sobreajuste. Esto significa que el modelo ha "memorizado" los datos de entrenamiento en lugar de aprender patrones generalizables. En la siguiente secci√≥n, utilizaremos validaci√≥n cruzada para obtener una estimaci√≥n m√°s robusta del rendimiento de generalizaci√≥n.
            </div>
        </div>

        <div class="content-section">
            <h2 id="cross-validation">Etapa 6: Cross Validation y Selecci√≥n de Modelos</h2>
            
            <p>La validaci√≥n cruzada (cross-validation) es una t√©cnica fundamental para estimar de manera m√°s robusta el rendimiento de generalizaci√≥n de nuestros modelos. En esta etapa, evaluaremos los modelos m√°s prometedores utilizando validaci√≥n cruzada de K-folds.</p>
            
            <h3>Implementaci√≥n de Cross Validation</h3>
            
<pre><code class="language-python">from sklearn import model_selection

# Lista para almacenar cada uno los modelos seleccionados para el cross validation
models = []

# Almacenando los modelos como una tupla (nombre, modelo)
models.append(('Elastic_net', ElasticNet(alpha=1, l1_ratio=0.5, max_iter=100000, warm_start=True)))
models.append(('Kneighbors', KNeighborsRegressor(n_neighbors=10)))
models.append(('Decision_tree', DecisionTreeRegressor(max_depth=2)))
models.append(('SVR', SVR(kernel='linear', epsilon=0.05, C=0.3)))

# Semilla para obtener los mismos resultados de pruebas
seed = 2
results = []
names = []
scoring = 'neg_mean_absolute_error'

for name, model in models:
    # Kfold cross validation
    kfold = model_selection.KFold(n_splits=10)
    model_pipe = Pipeline(steps=[("preprocessor", preprocessor),
                                ("model", model)])
    # X train, y train
    cv_results = model_selection.cross_val_score(model_pipe, X_train, y_train, cv=kfold, scoring=scoring)
    # la m√©trica neg_mean_absolute_error se debe convertir en positiva
    cv_results = np.abs(cv_results)
    results.append(cv_results)
    names.append(name)
    msg = f"{name}: {cv_results.mean():.2f} (¬±{cv_results.std():.2f})"
    print(msg)</code></pre>
            
<pre class="output"><code class="language-shell">Elastic_net: 2120.58 (¬±1023.35)
Kneighbors: 2566.21 (¬±1188.78)
Decision_tree: 2494.75 (¬±1103.84)
SVR: 2445.58 (¬±1048.04)</code></pre>
            
            <p>Los resultados muestran el error absoluto medio (MAE) y su desviaci√≥n est√°ndar a trav√©s de 10 folds. ElasticNet tiene el MAE m√°s bajo, pero todos los modelos muestran una alta variabilidad en sus resultados.</p>
            
            <h3>Visualizaci√≥n de resultados de Cross Validation</h3>
            
<pre><code class="language-python"># Visualizaci√≥n de resultados de cross validation mediante boxplots
plt.figure(figsize=(8, 4))
result_df = pd.DataFrame(results, index=names).T
sns.boxplot(data=result_df)
plt.title("Resultados de Cross Validation")
plt.show()

# Visualizaci√≥n de resultados de cada fold
plt.figure(figsize=(8, 4))
sns.lineplot(data=result_df)
plt.title("Resultados de cada Kfold")
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%205.png" alt="Boxplot de resultados de validaci√≥n cruzada">
                <div class="caption">Boxplot mostrando la distribuci√≥n de MAE en los 10 folds para cada modelo</div>
            </div>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%205_1.png" alt="L√≠neas de resultados por fold">
                <div class="caption">Variaci√≥n del MAE en cada fold para los diferentes modelos</div>
            </div>
            
            <h3>Comparaci√≥n estad√≠stica de modelos</h3>
            
            <p>Realizamos una prueba estad√≠stica (ANOVA) para determinar si las diferencias entre los modelos son significativas:</p>
            
<pre><code class="language-python"># Comparaci√≥n estad√≠stica de modelos
from scipy.stats import f_oneway

model1 = result_df['Elastic_net']
model2 = result_df['Kneighbors']
model3 = result_df['Decision_tree']
model4 = result_df['SVR']

statistic, p_value = f_oneway(model1, model2, model3, model4)
print(f'Statistic: {statistic}')
print(f'p_value: {p_value}')

alpha = 0.05  # nivel de significancia
if p_value < alpha:
    print("Existe una diferencia estad√≠sticamente "
          "significativa en los resultados de"
          " cross-validation de los modelos.")
else:
    print("No existe una diferencia estad√≠sticamente "
          "significativa en los resultados de "
          "cross-validation de los modelos.")</code></pre>
            
<pre class="output"><code class="language-shell">Statistic: 0.4463637923536907
p_value: 0.721363278798939
No existe una diferencia estad√≠sticamente significativa en los resultados de cross-validation de los modelos.</code></pre>
            
            <div class="note">
                La prueba estad√≠stica indica que, a pesar de las diferencias num√©ricas en los promedios de MAE, estas diferencias no son estad√≠sticamente significativas (p-value > 0.05). Esto puede deberse a la alta variabilidad en los resultados, posiblemente causada por el tama√±o limitado del conjunto de datos.
            </div>
            
            <p>A pesar de que no hay diferencias estad√≠sticamente significativas, seleccionamos ElasticNet para la optimizaci√≥n de hiperpar√°metros debido a que:</p>
            <ol>
                <li>Presenta el MAE m√°s bajo en la validaci√≥n cruzada</li>
                <li>La regularizaci√≥n combinada de L1 y L2 ayuda a controlar el sobreajuste</li>
                <li>Proporciona un modelo interpretable donde los coeficientes indican la importancia de las caracter√≠sticas</li>
            </ol>
        </div>

        <div class="content-section">
            <h2 id="optimizacion-hiperparametros">Etapa 7: Optimizaci√≥n de Hiperpar√°metros</h2>
            
            <p>Ahora que hemos seleccionado ElasticNet como nuestro modelo principal, procederemos a optimizar sus hiperpar√°metros para mejorar su rendimiento. Los principales hiperpar√°metros a ajustar son:</p>
            
            <ul>
                <li><strong>alpha</strong>: Controla la fuerza de la regularizaci√≥n. Valores m√°s altos reducen la complejidad del modelo.</li>
                <li><strong>l1_ratio</strong>: Controla el balance entre regularizaci√≥n L1 (Lasso) y L2 (Ridge). Un valor de 1 equivale a pure Lasso, y 0 a pure Ridge.</li>
            </ul>
            
            <h3>Grid Search para ElasticNet</h3>
            
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV

# Optimizaci√≥n de Elastic Net Regression
parameters = {
    'model__alpha': [0.2, 0.4, 0.6, 0.8, 1.0],
    'model__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]
}
elastic_net_pipe = Pipeline(steps=[("preprocessor", preprocessor),
                            ("model", ElasticNet(max_iter=100000, warm_start=True))])
grid_search = GridSearchCV(elastic_net_pipe, parameters, cv=5,
                          return_train_score=True,
                          scoring='neg_mean_absolute_error')
grid_search.fit(X_train, y_train);

# Resultados de la hiperparametrizaci√≥n
# La medida neg_mean_absolute_error se debe convertir en positiva
print(f"Mejor resultado = {abs(grid_search.best_score_)}")
print(f"Mejor std = {grid_search.cv_results_['std_test_score'][grid_search.best_index_]}")
print(f"Mejor par√°metros = {grid_search.best_params_}")</code></pre>
            
<pre class="output"><code class="language-shell">Mejor resultado = 1756.596029557147
Mejor std = 426.13874790189107
Mejor par√°metros = {'model__alpha': 0.2, 'model__l1_ratio': 0.9}</code></pre>
            
            <p>La b√∫squeda en cuadr√≠cula (grid search) nos indica que los mejores hiperpar√°metros para nuestro modelo ElasticNet son:</p>
            <ul>
                <li><strong>alpha = 0.2</strong>: Un valor relativamente bajo, lo que sugiere que se necesita menos regularizaci√≥n de lo que inicialmente configuramos.</li>
                <li><strong>l1_ratio = 0.9</strong>: Un valor cercano a 1, lo que indica que el modelo se beneficia principalmente de la regularizaci√≥n L1 (similar a Lasso), que promueve la selecci√≥n de caracter√≠sticas.</li>
            </ul>
            
            <h3>Evaluaci√≥n del modelo optimizado</h3>
            
            <p>Evaluamos el rendimiento del modelo ElasticNet con los hiperpar√°metros optimizados:</p>
            
<pre><code class="language-python">model = ElasticNet(
        alpha=grid_search.best_params_['model__alpha'],
        l1_ratio=grid_search.best_params_['model__l1_ratio'],
        max_iter=100000,
        warm_start=True
    )

# Evaluar el modelo con los mejores hiperpar√°metros
elastic_net_pipe = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", model)
])
elastic_net_model = elastic_net_pipe.fit(X_train, y_train)
y_pred = elastic_net_model.predict(X_test)
y_pred_train = elastic_net_model.predict(X_train)

print('Mean Absolute Error en conjunto de Prueba: ', mean_absolute_error(y_test, y_pred))</code></pre>
            
<pre class="output"><code class="language-shell">Mean Absolute Error en conjunto de Prueba:  2393.867610873727</code></pre>
            
            <div class="note">
                El error medio absoluto (MAE) de nuestro modelo optimizado en el conjunto de prueba es de aproximadamente 2,394. Considerando que el rango de precios en nuestro dataset va desde 5,118 hasta 45,400 d√≥lares, este error representa aproximadamente un 6-7% del rango total, lo cual es razonable para este problema.
            </div>
            
            <h3>Visualizaci√≥n de Errores de Predicci√≥n</h3>
            
<pre><code class="language-python"># Visualizaci√≥n de errores de predicci√≥n
from sklearn.metrics import PredictionErrorDisplay

PredictionErrorDisplay.from_predictions(y_true=y_test,
                                       y_pred=y_pred,
                                       kind="actual_vs_predicted");

PredictionErrorDisplay.from_predictions(y_true=y_test,
                                       y_pred=y_pred,
                                       kind="residual_vs_predicted");</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%206.png" alt="Valores reales vs predichos">
                <div class="caption">Gr√°fico de valores reales vs predichos</div>
            </div>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%206_1.png" alt="Residuos vs valores predichos">
                <div class="caption">Gr√°fico de residuos vs valores predichos</div>
            </div>
            
            <p>Estas visualizaciones nos proporcionan informaci√≥n importante sobre el comportamiento de nuestro modelo:</p>
            
            <ul>
                <li><strong>Gr√°fico de valores reales vs predichos</strong>: Los puntos cercanos a la diagonal representan predicciones precisas. Podemos observar que el modelo tiende a subestimar los precios m√°s altos y muestra mayor precisi√≥n en el rango medio-bajo.</li>
                <li><strong>Gr√°fico de residuos vs predichos</strong>: Idealmente, los residuos deber√≠an distribuirse aleatoriamente alrededor de cero sin patrones evidentes. El patr√≥n en forma de embudo (heteroscedasticidad) sugiere que la varianza del error aumenta con el precio, lo que es com√∫n en datos econ√≥micos.</li>
            </ul>
            
            <div class="tip">
                La heteroscedasticidad observada en los residuos podr√≠a sugerir que una transformaci√≥n logar√≠tmica de la variable objetivo podr√≠a mejorar el rendimiento del modelo, ya que esta transformaci√≥n suele estabilizar la varianza y mejorar la linealidad en datos econ√≥micos como los precios.
            </div>
        </div>

        <div class="content-section">
            <h2 id="interpretacion-modelo">Etapa 8: Interpretaci√≥n del Modelo</h2>
            
            <p>Una vez optimizado nuestro modelo, es fundamental entender qu√© caracter√≠sticas influyen m√°s en las predicciones. Esto proporciona insights valiosos sobre los factores que afectan el precio de los autom√≥viles.</p>
            
            <h3>An√°lisis de Importancia de Caracter√≠sticas</h3>
            
            <p>Utilizaremos la t√©cnica de "Permutation Importance" para evaluar la importancia de cada caracter√≠stica en el modelo:</p>
            
<pre><code class="language-python">from sklearn.inspection import permutation_importance

# Calculamos importancia por permutaci√≥n (funciona con el pipeline completo)
imps = permutation_importance(elastic_net_pipe, X_test, y_test,
                              n_repeats=5,
                              scoring="neg_mean_absolute_error",
                              n_jobs=-1, random_state=42)

# Visualizamos los resultados
fig = plt.figure(figsize=(10, 8))
perm_sorted_idx = imps.importances_mean.argsort()
plt.boxplot(imps.importances[perm_sorted_idx].T, vert=False, labels=X_test.columns[perm_sorted_idx])
plt.title("Permutation Importances (test set)");

# Seleccionamos las caracter√≠sticas m√°s importantes seg√∫n permutation importance
cols_seleccionadas = X_test.columns[perm_sorted_idx][-8:].tolist()  # Top 8 caracter√≠sticas
print("Caracter√≠sticas m√°s importantes seg√∫n permutation importance:")
print(cols_seleccionadas)</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/regresion%207.png" alt="Importancia de caracter√≠sticas por permutaci√≥n">
                <div class="caption">Importancia de caracter√≠sticas seg√∫n el m√©todo de permutaci√≥n</div>
            </div>
            
<pre class="output"><code class="language-shell">Caracter√≠sticas m√°s importantes seg√∫n permutation importance:
['city-mpg', 'horsepower', 'drive-wheels', 'width', 'curb-weight', 'wheel-base', 'make', 'engine-size']</code></pre>
            
            <h3>Interpretaci√≥n de las caracter√≠sticas m√°s importantes</h3>
            
            <p>Los resultados de la importancia por permutaci√≥n confirman muchas de nuestras observaciones iniciales del an√°lisis exploratorio. Las caracter√≠sticas m√°s influyentes en el precio de un autom√≥vil son:</p>
            
            <ol>
                <li><strong>engine-size</strong>: El tama√±o del motor es el factor m√°s determinante del precio, lo que es intuitivo ya que motores m√°s grandes suelen asociarse con autom√≥viles de mayor potencia y precio.</li>
                <li><strong>horsepower</strong>: La potencia del motor, estrechamente relacionada con el rendimiento y las prestaciones del veh√≠culo.</li>
                <li><strong>curb-weight</strong>: El peso del veh√≠culo, que se correlaciona tanto con el tama√±o como con la calidad de los materiales.</li>
                <li><strong>width</strong>: La anchura del veh√≠culo, asociada con el espacio interior y posiblemente la categor√≠a del autom√≥vil.</li>
                <li><strong>highway-mpg</strong> y <strong>city-mpg</strong>: La eficiencia de combustible, que presenta una relaci√≥n negativa con el precio.</li>
                <li><strong>length</strong>: La longitud del veh√≠culo, otro indicador de su tama√±o y categor√≠a.</li>
                <li><strong>fuel-type</strong>: El tipo de combustible, que puede influir en el precio debido a diferencias en costos de producci√≥n y mercado objetivo.</li>
            </ol>
            
            <div class="note">
                El modelo ElasticNet selecciona caracter√≠sticas autom√°ticamente mediante regularizaci√≥n L1, asignando coeficientes cercanos a cero a las caracter√≠sticas menos importantes. Esto es especialmente √∫til en casos con alta dimensionalidad o multicolinealidad entre predictores.
            </div>
            
            <h3>Implicaciones para el negocio</h3>
            
            <p>Estos resultados tienen varias implicaciones √∫tiles:</p>
            
            <ul>
                <li><strong>Valoraci√≥n de veh√≠culos</strong>: Los concesionarios podr√≠an utilizar principalmente estas 8 caracter√≠sticas para estimar r√°pidamente el valor de un veh√≠culo.</li>
                <li><strong>Desarrollo de productos</strong>: Los fabricantes podr√≠an enfocarse en optimizar estas caracter√≠sticas espec√≠ficas seg√∫n su estrategia de posicionamiento de precios.</li>
                <li><strong>An√°lisis competitivo</strong>: Analizar c√≥mo diferentes marcas balancean estas caracter√≠sticas permite entender mejor sus estrategias de precios.</li>
            </ul>
            
            <div class="tip">
                Al construir aplicaciones pr√°cticas con este modelo, podr√≠a ser beneficioso crear un modelo simplificado que utilice solo las caracter√≠sticas m√°s importantes. Esto facilitar√≠a la implementaci√≥n y reducir la cantidad de datos necesarios para realizar predicciones.
            </div>
        </div>

        <div class="content-section">
            <h2 id="modelo-final">Etapa 9: Modelo Final y Guardado</h2>
            
            <p>En esta etapa final, guardamos nuestro modelo optimizado para uso futuro y demostramos c√≥mo utilizarlo para realizar nuevas predicciones. El guardado del modelo permite integrar nuestro trabajo en aplicaciones, servicios o flujos de trabajo automatizados.</p>
            
            <h3>Guardado del Modelo</h3>
            
            <p>Utilizamos la biblioteca joblib, que es eficiente para serializar modelos de scikit-learn:</p>
            
<pre><code class="language-python"># Guardado del modelo final
from joblib import dump  # librer√≠a de serializaci√≥n

# Grabar el modelo en un archivo
dump(elastic_net_model, 'elastic-model-auto.joblib')</code></pre>
            
<pre class="output"><code class="language-shell">['elastic-model-auto.joblib']</code></pre>
            
            <h3>Carga y Uso del Modelo</h3>
            
            <p>Demostramos c√≥mo cargar el modelo guardado y utilizarlo para realizar nuevas predicciones:</p>
            
<pre><code class="language-python">import pandas as pd
from joblib import load

# Cargar el modelo
modelo = load('elastic-model-auto.joblib')
print(modelo)</code></pre>
            
<pre class="output"><code class="language-shell">Pipeline(steps=[('preprocessor',
                 ColumnTransformer(
                     transformers=[('numericas',
                                    Pipeline(steps=[('imputer',
                                                     SimpleImputer(strategy='median'))]),
                                    ['symboling', 'normalized-losses',
                                     'wheel-base', 'length', 'width', 'height',
                                     'curb-weight', 'engine-size', 'bore',
                                     'stroke', 'compression-ratio', 'horsepower',
                                     'peak-rpm', 'city-mpg', 'highway-mpg']),
                                   ('categoricas',
                                    Pipeline(steps=[('imputer',
                                                     SimpleImputer(strategy='most_frequent')),
                                                    ('onehot',
                                                     OneHotEncoder(handle_unknown='ignore'))]),
                                    ['make', 'fuel-type', 'aspiration',
                                     'body-style', 'drive-wheels',
                                     'engine-location', 'engine-type',
                                     'fuel-system']),
                                   ('categoricas ordinales',
                                    Pipeline(steps=[('ordenc',
                                                     OrdinalEncoder(handle_unknown='use_encoded_value',
                                                                    unknown_value=nan)),
                                                    ('imputer',
                                                     SimpleImputer(strategy='most_frequent'))]),
                                    ['num-of-doors', 'num-of-cylinders'])])),
                ('model',
                 ElasticNet(alpha=0.2, l1_ratio=0.9, max_iter=100000,
                            warm_start=True))])</code></pre>
            
            <p>Ahora, tomamos algunos datos de ejemplo para realizar predicciones con el modelo cargado:</p>
            
<pre><code class="language-python"># Tomar dos datos de entrada para realizar la predicci√≥n
datos_prueba = X_features.sample(2)
datos_prueba</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/test_data.png" alt="Datos de prueba para predicci√≥n">
                <div class="caption">Muestra de datos de prueba para realizar predicciones</div>
            </div>
            
<pre><code class="language-python"># Resultados de predicci√≥n con el modelo
predicciones = modelo.predict(datos_prueba)
print(predicciones)</code></pre>
            
<pre class="output"><code class="language-shell">[16371.67580828  7975.86683396]</code></pre>
            
            <h3>Consideraciones para implementaci√≥n en producci√≥n</h3>
            
            <p>Al implementar este modelo en un entorno de producci√≥n, debemos considerar:</p>
            
            <ol>
                <li><strong>Validaci√≥n de entradas</strong>: Asegurar que las nuevas entradas est√©n en el mismo formato y rango que los datos de entrenamiento.</li>
                <li><strong>Monitoreo de rendimiento</strong>: Implementar sistemas para monitorear el rendimiento del modelo a lo largo del tiempo, detectando posibles degradaciones.</li>
                <li><strong>Actualizaci√≥n peri√≥dica</strong>: Planificar actualizaciones peri√≥dicas del modelo con datos nuevos para mantener su precisi√≥n frente a cambios en el mercado.</li>
                <li><strong>Manejo de errores</strong>: Implementar manejo robusto de errores y excepciones para casos donde los datos de entrada sean problem√°ticos.</li>
                <li><strong>Documentaci√≥n</strong>: Documentar claramente las caracter√≠sticas requeridas, sus formatos y cualquier preprocesamiento espec√≠fico necesario.</li>
            </ol>
            
            <div class="note">
                El pipeline completo incluye tanto el preprocesamiento como el modelo, lo que simplifica enormemente la implementaci√≥n, ya que no es necesario replicar manualmente los pasos de preprocesamiento cada vez que se realiza una predicci√≥n.
            </div>
            
            <div class="tip">
                En entornos de producci√≥n, considera encapsular el modelo dentro de una API REST, lo que facilitar√° su integraci√≥n con diferentes sistemas y aplicaciones, y permitir√° un control centralizado sobre las versiones y actualizaciones del modelo.
            </div>
        </div>

        <div class="content-section">
            <h2 id="material-practica">Material de Pr√°ctica</h2>

            <p>Para consolidar los conceptos aprendidos en este cap√≠tulo, te invitamos a realizar los siguientes ejercicios pr√°cticos:</p>

            <ul class="resources-list">
                <li><strong><a href="https://colab.research.google.com/drive/1GXhDiFw5DgOOoNkghgETf5DPP7b6en3A" target="_blank">Construcci√≥n de un proyecto de regresi√≥n completo</a></strong> - Notebook con un flujo de trabajo completo para problemas de regresi√≥n, similar al presentado en este cap√≠tulo.</li>
            </ul>
            
            <div class="tip">
                <strong>Ejercicio pr√°ctico:</strong> Intenta replicar el flujo de trabajo presentado en este cap√≠tulo con un dataset diferente, como el dataset de Boston Housing o California Housing disponibles en scikit-learn. Compara el rendimiento de diferentes modelos y analiza qu√© caracter√≠sticas son m√°s importantes en cada caso.
            </div>

            <h2 id="referencias">Referencias</h2>

            <p>Para profundizar en los conceptos de regresi√≥n y t√©cnicas relacionadas, recomendamos consultar estos recursos:</p>

            <ul class="resources-list">
                <li><strong><a href="https://scikit-learn.org/stable/modules/linear_model.html" target="_blank">Documentaci√≥n oficial de modelos lineales en scikit-learn</a></strong> - Referencia completa sobre implementaci√≥n de modelos de regresi√≥n en Python.</li>
                <li><strong><a href="https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques" target="_blank">Competencia de Kaggle: House Prices</a></strong> - Competencia popular para practicar t√©cnicas avanzadas de regresi√≥n.</li>
                <li><strong><a href="https://www.statsmodels.org/stable/regression.html" target="_blank">Statsmodels</a></strong> - Biblioteca Python que ofrece implementaciones de modelos estad√≠sticos con enfoque en la inferencia estad√≠stica.</li>
            </ul>
            
            <div class="note">
                Recuerda que la pr√°ctica constante es fundamental para dominar las t√©cnicas de regresi√≥n. Intenta aplicar lo aprendido a diferentes datasets y problemas del mundo real para consolidar tu comprensi√≥n y desarrollar intuici√≥n sobre cu√°ndo y c√≥mo aplicar cada t√©cnica.
            </div>
        </div>

        <div class="content-section">
            <div class="feedback-section">
                <h3>¬øTe ha resultado √∫til esta p√°gina?</h3>
                <div class="feedback-buttons">
                    <button class="btn feedback-btn feedback-yes">
                        <span class="feedback-icon">üòä</span> S√≠
                    </button>
                    <button class="btn feedback-btn feedback-no">
                        <span class="feedback-icon">ü§î</span> No
                    </button>
                </div>
            </div>
     
            <!-- Nueva secci√≥n de navegaci√≥n entre cap√≠tulos -->
            <div class="chapter-navigation">
                <a href="machine_learning.html" class="nav-btn nav-prev">
                    <span class="nav-icon">‚óÄ</span> Cap√≠tulo Anterior
                </a>
                <a href="classification.html" class="nav-btn nav-next">
                    Cap√≠tulo Siguiente <span class="nav-icon">‚ñ∂</span>
                </a>
            </div>
        </div>
     
        <div class="footer">
            <p>¬© 2025 Python para Ciencia de Datos - Ph.D. Antonio Escamilla P.</p>
     
            <div class="license-icons">
                <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" target="_blank" class="license-link" title="Creative Commons BY-NC-ND 4.0">
                    <!-- √çcono CC -->
                    <span class="icon-tooltip" data-tooltip="Creative Commons">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <text x="12" y="14" font-family="Arial, sans-serif" font-size="8" font-weight="bold" text-anchor="middle" fill="var(--accent-green)">CC</text>
                        </svg>
                    </span>
                    
                    <!-- √çcono BY (Atribuci√≥n) -->
                    <span class="icon-tooltip" data-tooltip="Atribuci√≥n">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <circle cx="12" cy="8" r="2.5" fill="var(--accent-green)"/>
                            <path d="M8,16 L16,16 L16,13 C16,11.5 14,11 12,11 C10,11 8,11.5 8,13 L8,16 Z" fill="var(--accent-green)"/>
                        </svg>
                    </span>
                    
                    <!-- √çcono NC (No Comercial) -->
                    <span class="icon-tooltip" data-tooltip="No Comercial">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <text x="12" y="15" font-family="Arial, sans-serif" font-size="10" font-weight="bold" text-anchor="middle" fill="var(--accent-green)">$</text>
                            <line x1="6" y1="6" x2="18" y2="18" stroke="var(--accent-green)" stroke-width="2"/>
                        </svg>
                    </span>
                    
                    <!-- √çcono ND (Sin Derivadas) -->
                    <span class="icon-tooltip" data-tooltip="Sin Derivadas">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <rect x="7" y="10" width="10" height="1.5" fill="var(--accent-green)"/>
                            <rect x="7" y="13" width="10" height="1.5" fill="var(--accent-green)"/>
                        </svg>
                    </span>
                </a>
            </div>
        </div>
     </div>
     
     <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Aplicar resaltado a todos los bloques de c√≥digo
            document.querySelectorAll('pre code').forEach(function(block) {
                hljs.highlightElement(block);
            });
            
            const hamburgerMenu = document.querySelector('.hamburger-menu');
            const hamburgerButton = document.querySelector('.hamburger-button');
            
            // Alternar men√∫ al hacer clic en el bot√≥n
            hamburgerButton.addEventListener('click', function() {
                hamburgerMenu.classList.toggle('active');
            });
     
            // Cerrar men√∫ al hacer clic en un enlace
            const menuLinks = document.querySelectorAll('.menu-content a');
            menuLinks.forEach(link => {
                link.addEventListener('click', function() {
                    hamburgerMenu.classList.remove('active');
                });
            });
     
            // Cerrar men√∫ al hacer clic fuera de √©l
            document.addEventListener('click', function(event) {
                if (!hamburgerMenu.contains(event.target)) {
                    hamburgerMenu.classList.remove('active');
                }
            });
        });
     </script>
</body>