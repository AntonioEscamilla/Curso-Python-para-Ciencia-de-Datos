<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clasificación con Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/atom-one-dark.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <style>
        :root {
            --primary-dark: #04142b;
            --primary-medium: #142a45;
            --accent-green: #00ff85;
            --text-light: #e6e8ea;
            --text-grey: #a3a8ae;
            --progress-bg: #1f3754;
            --code-bg: #1e1e1e;
            --output-border: #b07ff3;
            
            /* Colores para los recuadros informativos */
            --note-bg: #c5e0ff;
            --note-border: #0d47a1;
            --warning-bg: #ffe082;
            --warning-border: #e65100;
            --tip-bg: #b9f6ca;
            --tip-border: #1b5e20;
            --info-text: #222222;
        }
        
        body {
            font-family: 'Inter', 'Segoe UI', system-ui, -apple-system, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 0;
            color: var(--text-light);
            background-color: var(--primary-dark);
        }
        
        .course-header {
            background-color: var(--primary-dark);
            padding: 1.5rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        .course-label {
            color: var(--text-grey);
            font-size: 0.9rem;
            font-weight: 500;
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-bottom: 0.5rem;
        }
        
        .course-title {
            color: var(--text-light);
            font-size: 2rem;
            font-weight: 700;
            margin: 0.5rem 0;
        }
        
        .course-author {
            color: var(--text-grey);
            font-size: 1rem;
            margin-top: 0.5rem;
        }
        
        .progress-container {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 1.5rem 0;
        }
        
        .progress-bar {
            flex-grow: 1;
            height: 6px;
            background-color: var(--progress-bg);
            border-radius: 3px;
            margin-right: 15px;
            position: relative;
        }
        
        .progress-fill {
            height: 100%;
            width: 0%;
            background-color: var(--accent-green);
            border-radius: 3px;
        }
        
        .progress-info {
            display: flex;
            align-items: center;
            color: var(--text-grey);
            font-size: 0.9rem;
        }
        
        .progress-info i {
            margin-right: 5px;
        }
        
        .btn {
            background-color: var(--accent-green);
            color: var(--primary-dark);
            border: none;
            border-radius: 6px;
            padding: 0.8rem 1.8rem;
            font-size: 1rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease;
        }
        
        .btn:hover {
            opacity: 0.9;
            transform: translateY(-1px);
        }
        
        .btn-practice {
            background-color: transparent;
            border: 1px solid rgba(255, 255, 255, 0.2);
            color: var(--text-light);
            display: flex;
            align-items: center;
            padding: 0.6rem 1.2rem;
        }
        
        .btn-practice i {
            margin-right: 8px;
            color: #ff8a00;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }
        
        nav {
            background-color: var(--primary-medium);
            padding: 1rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
        }
        
        nav ul {
            list-style-type: none;
            margin: 0;
            padding: 0;
            display: flex;
            flex-wrap: wrap;
            gap: 1rem;
        }
        
        nav li {
            margin-bottom: 0.5rem;
        }
        
        nav a {
            color: var(--text-grey);
            text-decoration: none;
            font-weight: 500;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            transition: all 0.2s ease;
        }
        
        nav a:hover, nav a.active {
            color: var(--text-light);
            background-color: rgba(255, 255, 255, 0.1);
        }
        
        nav a.active {
            border-left: 3px solid var(--accent-green);
        }
        
        .content-section {
            background-color: var(--primary-medium);
            padding: 2rem;
            border-radius: 10px;
            margin-bottom: 2rem;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
        }
        
        h1, h2, h3 {
            color: var(--text-light);
            font-weight: 700;
        }
        
        h1 {
            font-size: 2.2rem;
            margin-bottom: 1.5rem;
        }
        
        h2 {
            font-size: 1.8rem;
            margin-top: 2.5rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        h3 {
            font-size: 1.4rem;
            margin-top: 2rem;
            margin-bottom: 0.75rem;
            color: var(--accent-green);
        }
        
        code {
            font-family: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
            background-color: rgba(0, 0, 0, 0.3);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            color: #e6e6e6;
        }
        
        /* Para código dentro de los bloques de información con texto oscuro */
        .note code, .warning code, .tip code {
            background-color: rgba(0, 0, 0, 0.1);
            color: var(--info-text);
            font-weight: 500;
        }
        
        /* Estilos para bloques de código */
        pre {
            background-color: var(--code-bg) !important;
            padding: 1rem;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
            position: relative;
            border-left: 3px solid var(--accent-green);
            line-height: 1.5;
        }
        
        pre code,
        pre code.hljs,
        .hljs {
            background-color: var(--code-bg) !important;
            padding: 0;
            color: #d4d4d4;
        }
        
        /* Forzar que no haya ningún fondo en los elementos dentro del código */
        pre *, pre code *, pre code.hljs * {
            background-color: transparent !important;
        }
        
        /* Mantener colores de sintaxis */
        .hljs-comment {
            color: #6a9955 !important;
            background-color: transparent !important;
        }
        
        .hljs-keyword, .hljs-built_in, .hljs-literal {
            color: #ff7b72 !important;
            background-color: transparent !important;
        }
        
        .hljs-string {
            color: #ce9178 !important;
            background-color: transparent !important;
        }
        
        .hljs-number {
            color: #b5cea8 !important;
            background-color: transparent !important;
        }
        
        .hljs-function, .hljs-title.function_ {
            color: #dcdcaa !important;
            background-color: transparent !important;
        }
        
        .hljs-variable {
            color: #9cdcfe !important;
            background-color: transparent !important;
        }
        
        .output {
            background-color: #000000;
            border-left: 4px solid var(--output-border);
            padding: 1rem;
            margin: 1rem 0;
            color: #f1f1f1;
            font-family: 'Courier New', Courier, monospace;
            font-size: 0.9rem;
            border-radius: 0 8px 8px 0;
            box-shadow: inset 0 0 10px rgba(0, 0, 0, 0.6);
        }
        
        /* Estilos para recuadros informativos */
        .note, .warning, .tip {
            border-radius: 6px;
            padding: 0.8rem 1.2rem;
            margin: 1.5rem 0;
            position: relative;
            font-size: 0.95rem;
            line-height: 1.5;
            border-left-width: 6px;
            border-left-style: solid;
            color: var(--info-text);
        }
        
        /* Estilo para NOTA - azul */
        .note {
            background-color: var(--note-bg);
            border-left-color: var(--note-border);
        }
        
        .note::before {
            content: "Nota:";
            font-weight: 700;
            color: var(--note-border);
            margin-right: 0.3rem;
        }
        
        /* Estilo para ADVERTENCIA - amarillo/naranja */
        .warning {
            background-color: var(--warning-bg);
            border-left-color: var(--warning-border);
        }
        
        .warning::before {
            content: "Advertencia:";
            font-weight: 700;
            color: var(--warning-border);
            margin-right: 0.3rem;
        }
        
        /* Estilo para TIP - verde */
        .tip {
            background-color: var(--tip-bg);
            border-left-color: var(--tip-border);
        }
        
        .tip::before {
            content: "Tip:";
            font-weight: 700;
            color: var(--tip-border);
            margin-right: 0.3rem;
        }
        
        .welcome-message {
            font-size: 1.1rem;
            line-height: 1.7;
            margin-bottom: 2rem;
            color: var(--text-grey);
        }
        
        .highlight {
            color: var(--accent-green);
            font-weight: 600;
        }
        
        .icon-clock:before {
            content: "⏱️";
            margin-right: 5px;
        }
        
        .icon-dumbbell:before {
            content: "🏋️";
            margin-right: 5px;
        }
        
        .footer {
            text-align: center;
            margin-top: 3rem;
            padding: 1rem;
            color: var(--text-grey);
            border-top: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        /* Estilos para imágenes */
        .img-container {
            margin: 2rem 0;
            text-align: center;
        }
        
        .img-container img {
            max-width: 100%;
            border-radius: 8px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
        }
        
        .caption {
            color: var(--text-grey);
            font-size: 0.9rem;
            margin-top: 0.5rem;
            font-style: italic;
        }

        @media (max-width: 768px) {
            .container {
                padding: 1rem;
            }
            
            .course-title {
                font-size: 1.6rem;
            }
            
            nav ul {
                flex-direction: column;
            }
        }

        .table-container {
            margin: 2rem auto;
            max-width: 800px; /* Ancho máximo para centrar */
        }

        .builtin-functions {
            width: 100%;
            border-collapse: collapse;
            background-color: var(--primary-medium);
            color: var(--text-light);
            margin: 0 auto; /* Centrar la tabla */
        }

        .builtin-functions tr:nth-child(odd) {
            background-color: var(--primary-medium); /* Primer tono de azul */
        }

        .builtin-functions tr:nth-child(even) {
            background-color: rgba(30, 60, 100, 0.6); /* Segundo tono de azul más claro */
        }

        .builtin-functions td {
            padding: 10px 15px;
            text-align: left;
            border: none; /* Eliminar bordes laterales */
            border-bottom: 1px solid rgba(255, 255, 255, 0.2); /* Línea horizontal blanca */
        }

        /* Doble línea en la parte superior de la primera fila */
        .builtin-functions tr:first-child td {
            border-top: 3px double rgba(255, 255, 255, 0.4);
        }

        .builtin-functions code {
            font-family: 'JetBrains Mono', 'Fira Code', 'Consolas', monospace;
            color: var(--accent-green);
        }

        .builtin-functions tr:hover {
            background-color: rgba(255, 255, 255, 0.05);
        }

        .resources-list {
            margin: 1.5rem 0;
        }

        .resources-list li {
            margin-bottom: 1rem;
            line-height: 1.6;
        }

        .resources-list strong {
            color: var(--accent-green);
        }

        .resources-list {
            margin: 1.5rem 0;
        }
        
        .resources-list li {
            margin-bottom: 1rem;
            line-height: 1.6;
        }
        
        .resources-list strong {
            color: var(--accent-green);
        }
        
        .resources-list a {
            color: var(--accent-green) !important; /* Forzar color verde */
            text-decoration: none;
            transition: all 0.2s ease;
        }
        
        .resources-list a:hover {
            text-decoration: underline;
            opacity: 0.9; /* Ligero cambio de opacidad al pasar el cursor */
        }

        .feedback-section {
            background-color: var(--primary-medium);
            padding: 1.5rem;
            border-radius: 10px;
            margin: 2rem 0;
            text-align: center;
        }

        .feedback-section h3 {
            color: var(--text-light);
            margin-bottom: 1.2rem;
        }

        .feedback-buttons {
            display: flex;
            justify-content: center;
            gap: 1rem;
        }

        .feedback-btn {
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0.6rem 1.5rem;
            font-size: 1rem;
            border-radius: 6px;
            transition: all 0.2s ease;
            cursor: pointer;
        }

        .feedback-yes {
            background-color: rgba(0, 255, 133, 0.2);
            border: 1px solid var(--accent-green);
            color: var(--accent-green);
        }

        .feedback-no {
            background-color: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.3);
            color: var(--text-light);
        }

        .feedback-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }

        .feedback-icon {
            margin-right: 8px;
            font-size: 1.2rem;
        }

        .license-icons {
            display: inline-flex;
            gap: 0.5rem;
            margin-left: 1rem;
            align-items: center;
        }

        .license-link {
            display: flex;
            gap: 0.5rem;
            text-decoration: none;
        }

        .license-icon {
            width: 28px;
            height: 28px;
            transition: transform 0.2s ease;
        }

        .icon-tooltip {
            position: relative;
            cursor: pointer;
        }

        .icon-tooltip:hover .license-icon {
            transform: scale(1.1);
        }

        .icon-tooltip::after {
            content: attr(data-tooltip);
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background-color: var(--primary-dark);
            color: var(--text-light);
            padding: 0.3rem 0.6rem;
            border-radius: 4px;
            font-size: 0.8rem;
            white-space: nowrap;
            opacity: 0;
            pointer-events: none;
            transition: opacity 0.2s ease;
            box-shadow: 0 2px 6px rgba(0, 0, 0, 0.3);
            z-index: 100;
        }

        .icon-tooltip:hover::after {
            opacity: 1;
        }

        .hamburger-menu {
            position: fixed;
            top: 20px;
            right: 20px;
            z-index: 1000;
        }

        .hamburger-button {
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            width: 40px;
            height: 35px;
            background-color: var(--primary-medium);
            border: none;
            border-radius: 5px;
            padding: 8px;
            cursor: pointer;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
        }

        .bar {
            height: 3px;
            width: 100%;
            background-color: var(--accent-green);
            border-radius: 2px;
            transition: all 0.3s ease;
        }

        .menu-content {
            position: absolute;
            right: 0;
            top: 50px;
            width: 250px;
            background-color: var(--primary-medium);
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.3);
            padding: 1.5rem;
            transform: scale(0.95);
            transform-origin: top right;
            opacity: 0;
            visibility: hidden;
            transition: all 0.2s ease;
            max-height: 80vh;
            overflow-y: auto;
        }

        .menu-content h3 {
            color: var(--accent-green);
            margin-top: 0;
            margin-bottom: 1rem;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            padding-bottom: 0.5rem;
        }

        .menu-content ul {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .menu-content li {
            margin-bottom: 0.7rem;
        }

        .menu-content a {
            color: var(--text-light);
            text-decoration: none;
            display: block;
            padding: 0.5rem;
            border-radius: 4px;
            transition: all 0.2s ease;
        }

        .menu-content a:hover {
            background-color: rgba(255, 255, 255, 0.1);
            color: var(--accent-green);
        }

        /* Clase para mostrar/ocultar el menú */
        .hamburger-menu.active .menu-content {
            transform: scale(1);
            opacity: 1;
            visibility: visible;
        }

        /* Animación de las barras cuando está activo */
        .hamburger-menu.active .bar:nth-child(1) {
            transform: translateY(10px) rotate(45deg);
        }

        .hamburger-menu.active .bar:nth-child(2) {
            opacity: 0;
        }

        .hamburger-menu.active .bar:nth-child(3) {
            transform: translateY(-10px) rotate(-45deg);
        }

        /* Estilos para navegación entre capítulos */
        .chapter-navigation {
            display: flex;
            justify-content: space-between;
            margin-top: 2rem;
            padding-top: 1.5rem;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }

        .nav-btn {
            display: inline-flex;
            align-items: center;
            padding: 0.8rem 1.5rem;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.2s ease;
            background-color: var(--primary-medium);
            color: var(--text-light);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .nav-btn:hover {
            background-color: var(--accent-green);
            color: var(--primary-dark);
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }

        .nav-icon {
            font-size: 0.9rem;
            margin: 0 0.5rem;
        }

        .nav-prev .nav-icon {
            margin-right: 0.5rem;
            margin-left: 0;
        }

        .nav-next .nav-icon {
            margin-left: 0.5rem;
            margin-right: 0;
        }

        /* Para páginas con un solo botón de navegación (como la primera) */
        .chapter-navigation.single-button {
            justify-content: flex-end; /* Alinea el contenido al extremo derecho */
        }

        /* En pantallas pequeñas, ajustar la navegación para mejor visualización */
        @media (max-width: 768px) {
            .chapter-navigation {
                flex-direction: column;
                gap: 1rem;
            }

            .nav-btn {
                text-align: center;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="hamburger-menu">
        <button class="hamburger-button" aria-label="Abrir menú de navegación">
            <span class="bar"></span>
            <span class="bar"></span>
            <span class="bar"></span>
        </button>
        
        <div class="menu-content">
            <h3>Secciones</h3>
            <ul>
                <li><a href="#intro-clasificacion">Introducción a la Clasificación</a></li>
                <li><a href="#algoritmos-basicos">Algoritmos Básicos</a></li>
                <li><a href="#metricas-evaluacion">Métricas de Evaluación</a></li>
                <li><a href="#etapa-2-exploracion">Exploración de Datos</a></li>
                <li><a href="#etapa-3-limpieza">Limpieza de Datos</a></li>
                <li><a href="#etapa-4-conversion">Conversión de Datos</a></li>
                <li><a href="#etapa-5-exploracion">Exploración de Datos</a></li>
                <li><a href="#etapa-6-feature-engineering">Feature Engineering</a></li>
                <li><a href="#etapa-8-entrenamiento">Entrenamiento del Modelo</a></li>
                <li><a href="#etapa-9-validacion">Validación del Modelo</a></li>
                <li><a href="#etapa-10-optimizacion">Optimización del Modelo</a></li>
                <li><a href="#etapa-11-evaluacion">Evaluación del Modelo</a></li>
                <li><a href="#etapa-12-interpretacion">Interpretación de Resultados</a></li>
                <li><a href="#etapa-13-preparacion">Despliegue</a></li>
                <li><a href="#material-practica">Material de Práctica</a></li>
                <li><a href="#referencias">Referencias</a></li>
            </ul>
        </div>
    </div>
     
    <div class="course-header">
        <div class="container">
            <div class="course-label">CURSO</div>
            <h1 class="course-title">Python para Ciencia de Datos</h1>
            <div class="course-author">Ph.D. Antonio Escamilla P.</div>
            
            <div class="progress-container">
                <div class="progress-bar">
                    <div class="progress-fill" style="width: 87.5%;"></div>
                </div>
                <div class="progress-info">
                    <span class="icon-clock"></span>
                    2 sections to go
                </div>
            </div>
            
            <div style="display: flex; justify-content: space-between;">
                <button class="btn btn-practice" onclick="document.getElementById('material-practica').scrollIntoView({behavior: 'smooth'})">
                    <span class="icon-dumbbell"></span>
                    Practica
                </button>
                <button class="btn" onclick="window.location.href='clustering.html'">Continuar</button>
            </div>
        </div>
    </div>
     
    <div class="container">
        <nav>
            <ul>
                <li><a href="index.html">1. Introducción a Python</a></li>
                <li><a href="numpy.html">2. NumPy</a></li>
                <li><a href="pandas.html">3. Pandas</a></li>
                <li><a href="polars.html">4. Polars</a></li>
                <li><a href="visualization.html">5. Visualización</a></li>
                <li><a href="machine_learning.html">6. Machine Learning</a></li>
                <li><a href="regression.html">7. Regresión</a></li>
                <li><a href="classification.html" class="active">8. Clasificación</a></li>
                <li><a href="clustering.html">9. Clustering</a></li>
            </ul>
        </nav>
        
        <div class="content-section">
            <h1 id="intro-clasificacion">Capítulo 8: Algoritmos de Clasificación en Machine Learning</h1>
            
            <h2 id="que-es-clasificacion">¿Qué es la Clasificación?</h2>
            
            <p>La clasificación es una técnica de aprendizaje supervisado donde el objetivo es predecir a qué categoría o clase pertenece una observación. A diferencia de la regresión que predice valores continuos, la clasificación asigna etiquetas discretas o categorías.</p>
            
            <div class="img-container">
                <img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png" alt="Comparación de algoritmos de clasificación">
                <div class="caption">Comparación visual de diferentes algoritmos de clasificación (Fuente: Scikit-learn)</div>
            </div>
            
            <p>Los modelos de clasificación son ampliamente utilizados en numerosos campos:</p>
            
            <ul>
                <li><strong>Medicina</strong>: Diagnóstico de enfermedades, identificación de células cancerígenas</li>
                <li><strong>Finanzas</strong>: Detección de fraudes, evaluación de riesgos crediticios</li>
                <li><strong>Marketing</strong>: Segmentación de clientes, predicción de comportamientos de compra</li>
                <li><strong>Tecnología</strong>: Filtros de spam, reconocimiento facial, análisis de sentimientos</li>
                <li><strong>Industria</strong>: Control de calidad, mantenimiento predictivo</li>
            </ul>
            
            <h2 id="tipos-clasificacion">Tipos de Problemas de Clasificación</h2>
            
            <p>Existen diferentes tipos de problemas de clasificación, dependiendo de la naturaleza de las clases:</p>
            
            <h3>Clasificación Binaria</h3>
            
            <p>En la clasificación binaria, el objetivo es asignar cada observación a una de dos clases posibles.</p>
            
            <p>Ejemplos:</p>
            <ul>
                <li>Correo electrónico (spam / no spam)</li>
                <li>Diagnóstico médico (enfermo / sano)</li>
                <li>Aprobación de crédito (aprobado / rechazado)</li>
            </ul>
            
            <h3>Clasificación Multiclase</h3>
            
            <p>En la clasificación multiclase, el objetivo es asignar cada observación a una de varias clases posibles, donde cada observación pertenece exactamente a una clase.</p>
            
            <p>Ejemplos:</p>
            <ul>
                <li>Clasificación de especies de plantas</li>
                <li>Reconocimiento de dígitos manuscritos (0-9)</li>
                <li>Categorización de productos en un catálogo</li>
            </ul>
            
            <h3>Clasificación Multilabel</h3>
            
            <p>En la clasificación multilabel, cada observación puede pertenecer a múltiples clases simultáneamente.</p>
            
            <p>Ejemplos:</p>
            <ul>
                <li>Etiquetado de imágenes (puede contener "persona", "coche", "árbol")</li>
                <li>Categorización de artículos de noticias (puede ser "política" y "economía")</li>
                <li>Clasificación de películas por género (puede ser "drama" y "romántica")</li>
            </ul>
            
            <div class="note">
                La elección del algoritmo de clasificación adecuado depende no solo del tipo de problema, sino también de factores como el tamaño del conjunto de datos, la dimensionalidad, la interpretabilidad requerida y el equilibrio entre precisión y velocidad.
            </div>
        </div>

        <div class="content-section">
            <h2 id="algoritmos-basicos">Algoritmos Básicos de Clasificación</h2>
            
            <p>En este capítulo exploraremos los algoritmos de clasificación más utilizados en machine learning y cómo aplicarlos de manera efectiva en un proyecto real. La clasificación es una tarea supervisada donde el objetivo es predecir a qué clase o categoría pertenece una observación.</p>
            
            <h3>Principales Algoritmos de Clasificación</h3>
            
            <p>Existen numerosos algoritmos de clasificación, cada uno con sus fortalezas y debilidades. Los más utilizados incluyen:</p>
            
            <ul>
                <li><strong>Regresión Logística</strong>: Un algoritmo lineal que calcula la probabilidad de pertenencia a una clase utilizando la función logística.</li>
                <li><strong>Árboles de Decisión</strong>: Modelos que dividen los datos en subconjuntos basándose en el valor de las características, formando una estructura similar a un árbol.</li>
                <li><strong>Random Forest</strong>: Conjunto de árboles de decisión cuyas predicciones se combinan para mejorar la precisión y reducir el sobreajuste.</li>
                <li><strong>Support Vector Machines</strong>: Algoritmos que buscan un hiperplano óptimo para separar las clases en el espacio de características.</li>
                <li><strong>Naive Bayes</strong>: Clasificadores probabilísticos basados en el teorema de Bayes, que asumen independencia entre las características.</li>
                <li><strong>K-Nearest Neighbors</strong>: Clasificadores basados en la proximidad, que asignan la clase más común entre los k ejemplos más cercanos.</li>
                <li><strong>Gradient Boosting</strong>: Técnicas de ensamblaje que construyen modelos secuencialmente, donde cada uno intenta corregir los errores del anterior.</li>
                <li><strong>Redes Neuronales</strong>: Modelos inspirados en el cerebro humano capaces de aprender representaciones complejas.</li>
            </ul>

            <p>La elección del algoritmo adecuado depende de factores como la naturaleza de los datos, el tamaño del conjunto de datos, la velocidad necesaria para la predicción, la interpretabilidad requerida y la complejidad del problema.</p>
        </div>

        <div class="content-section">
            <h2 id="metricas-evaluacion">Métricas de Evaluación para Clasificación</h2>
            
            <p>Para evaluar el rendimiento de los modelos de clasificación, disponemos de diversas métricas, cada una enfocada en diferentes aspectos del desempeño:</p>
            
            <h3>Matriz de Confusión</h3>
            
            <p>Es una tabla que describe el rendimiento de un modelo de clasificación. Para un clasificador binario, contiene:</p>
            
            <ul>
                <li><strong>Verdaderos Positivos (TP)</strong>: Casos positivos correctamente clasificados</li>
                <li><strong>Falsos Positivos (FP)</strong>: Casos negativos incorrectamente clasificados como positivos</li>
                <li><strong>Falsos Negativos (FN)</strong>: Casos positivos incorrectamente clasificados como negativos</li>
                <li><strong>Verdaderos Negativos (TN)</strong>: Casos negativos correctamente clasificados</li>
            </ul>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20IA/confusion_matrix.png" alt="Matriz de confusión" width="60%">
                <div class="caption">Ejemplo de matriz de confusión visualizada (Fuente: Scikit-learn)</div>
            </div>

            <h3>Métricas derivadas de la Matriz de Confusión</h3>

            <ul>
                <li><strong>Exactitud (Accuracy)</strong>: Proporción de predicciones correctas.
                    <br>Accuracy = (TP + TN) / (TP + TN + FP + FN)</li>
                <li><strong>Precisión</strong>: De los casos predichos como positivos, cuántos son realmente positivos.
                    <br>Precision = TP / (TP + FP)</li>
                <li><strong>Sensibilidad o Recall</strong>: De los casos realmente positivos, cuántos fueron identificados correctamente.
                    <br>Recall = TP / (TP + FN)</li>
                <li><strong>F1-Score</strong>: Media armónica entre precisión y recall.
                    <br>F1 = 2 * (Precision * Recall) / (Precision + Recall)</li>
            </ul>

            <div class="tip">
                La elección de la métrica adecuada depende del contexto del problema. Por ejemplo, en detección de fraudes, la precisión puede ser más importante (minimizar falsos positivos), mientras que en diagnóstico médico, el recall puede ser prioritario (minimizar falsos negativos).
            </div>
        </div>

        <div class="content-section">
            <h2 id="workflow-clasificacion">Workflow Completo de Clasificación</h2>
            
            <p>A continuación, desarrollaremos un workflow completo para un problema de clasificación utilizando el conocido dataset del Titanic. Este conjunto de datos contiene información sobre los pasajeros del Titanic y el objetivo es predecir si un pasajero sobrevivió o no al naufragio.</p>
            
            <div class="note">
                Este workflow sigue las mejores prácticas en ciencia de datos e incluye todas las etapas necesarias: desde la carga y preparación de datos hasta la evaluación e interpretación del modelo final.
            </div>

            <h3 id="etapa-1-importacion">Etapa 1: Importación de Librerías y Datos</h3>

            <p>Comenzamos importando las librerías necesarias y cargando el conjunto de datos del Titanic:</p>
            
<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar el dataset del Titanic
titanic_df = pd.read_csv("https://www.openml.org/data/get_csv/16826755/phpMYEkMl")

# Visualizar una muestra de los datos
titanic_df.sample(5)</code></pre>
            
            <p>El dataset contiene información como la clase del pasajero (pclass), si sobrevivió o no (survived), nombre, sexo, edad, número de hermanos/cónyuges a bordo (sibsp), número de padres/hijos a bordo (parch), número de ticket, tarifa (fare), cabina, puerto de embarque, y más.</p>
            
            <h3 id="etapa-2-exploracion">Etapa 2: Exploración Inicial de los Datos</h3>
            
            <p>Antes de comenzar con el procesamiento, es importante entender la estructura y características de nuestros datos:</p>
            
<pre><code class="language-python"># Obtener información sobre el dataset
titanic_df.info()</code></pre>
            
<pre class="output"><code class="language-shell"><class 'pandas.core.frame.DataFrame'>
RangeIndex: 1309 entries, 0 to 1308
Data columns (total 14 columns):
 #   Column     Non-Null Count  Dtype 
---  ------     --------------  ----- 
 0   pclass     1309 non-null   int64 
 1   survived   1309 non-null   int64 
 2   name       1309 non-null   object
 3   sex        1309 non-null   object
 4   age        1309 non-null   object
 5   sibsp      1309 non-null   int64 
 6   parch      1309 non-null   int64 
 7   ticket     1309 non-null   object
 8   fare       1309 non-null   object
 9   cabin      1309 non-null   object
 10  embarked   1309 non-null   object
 11  boat       1309 non-null   object
 12  body       1309 non-null   object
 13  home.dest  1309 non-null   object
dtypes: int64(4), object(10)
memory usage: 143.3+ KB</code></pre>
            
            <p>Observamos que el conjunto de datos contiene 1,309 registros con 14 columnas. Algunos campos como 'age' y 'fare' aparecen como tipo 'object' cuando deberían ser numéricos, lo que indica posibles problemas con los datos.</p>
            
            <h3 id="etapa-3-limpieza">Etapa 3: Limpieza y Preparación de Datos</h3>
            
            <p>Para simplificar nuestro análisis, eliminaremos algunas columnas que no son relevantes para la predicción o que podrían causar filtraciones de datos (como 'boat' y 'body', que contienen información posterior al naufragio):</p>
            
<pre><code class="language-python"># Eliminar columnas no necesarias para la predicción
titanic_df = titanic_df.drop(['boat', 'body', 'home.dest', 'name', 'ticket', 'cabin'], axis='columns')
titanic_df.head()</code></pre>
            
            <p>Ahora tenemos un conjunto de datos más manejable con sólo las características esenciales: 'pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'fare' y 'embarked'.</p>
            
            <p>A continuación, identificamos y tratamos los valores faltantes:</p>
            
<pre><code class="language-python"># En este dataset, los valores faltantes están representados como '?'
titanic_df = titanic_df.replace('?', np.nan)

# Verificar valores nulos por columna
print(titanic_df.isna().sum())</code></pre>
            
<pre class="output"><code class="language-shell">pclass       0
survived     0
sex          0
age        263
sibsp        0
parch        0
fare         1
embarked     2
dtype: int64</code></pre>
            
            <p>Vemos que tenemos valores faltantes principalmente en la columna 'age' (263), y algunos en 'fare' (1) y 'embarked' (2).</p>
        </div>

        <div class="content-section">
            <h3 id="etapa-4-conversion">Etapa 4: Conversión de Tipos de Datos</h3>

            <p>Ahora que hemos identificado los valores faltantes, vamos a convertir cada columna al tipo de dato adecuado:</p>
            
<pre><code class="language-python"># Corregir las variables categóricas
cols_categoricas = ["pclass", "sex", "embarked"]
titanic_df[cols_categoricas] = titanic_df[cols_categoricas].astype("category")

# Corregir variable categórica ordinal
titanic_df["pclass"] = pd.Categorical(titanic_df["pclass"],
                                      categories=[3, 2, 1],
                                      ordered=True)

# Corregir las variables numéricas
cols_numericas = ["age", "fare"]
titanic_df[cols_numericas] = titanic_df[cols_numericas].astype("float")

# Corregir las variables booleanas
cols_booleanas = ["survived"]
titanic_df[cols_booleanas] = titanic_df[cols_booleanas].astype("bool")

# Verificar los tipos de datos
titanic_df.info()</code></pre>
            
<pre class="output"><code class="language-shell"><class 'pandas.core.frame.DataFrame'>
RangeIndex: 1309 entries, 0 to 1308
Data columns (total 8 columns):
 #   Column    Non-Null Count  Dtype   
---  ------    --------------  -----   
 0   pclass    1309 non-null   category
 1   survived  1309 non-null   bool    
 2   sex       1309 non-null   category
 3   age       1046 non-null   float64 
 4   sibsp     1309 non-null   int64   
 5   parch     1309 non-null   int64   
 6   fare      1308 non-null   float64 
 7   embarked  1307 non-null   category
dtypes: bool(1), category(3), float64(2), int64(2)
memory usage: 46.5 KB</code></pre>

            <h3 id="etapa-5-exploracion">Etapa 5: Análisis Exploratorio de Datos</h3>

            <p>Es importante explorar la distribución de la variable objetivo para entender el balance de clases:</p>
            
<pre><code class="language-python"># Visualizar la distribución de la variable objetivo (survived)
titanic_df["survived"].value_counts().plot(kind="bar", color=['skyblue', 'orange'])
plt.title('Distribución de Supervivencia')
plt.xlabel('Sobrevivió')
plt.ylabel('Número de pasajeros')
plt.xticks([0, 1], ['No (809)', 'Sí (500)'])
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_1.png" alt="Distribución de supervivencia en el Titanic">
                <div class="caption">Distribución de la variable objetivo: sobrevivientes vs no sobrevivientes</div>
            </div>
            
            <p>Observamos que hay una distribución desbalanceada, con más pasajeros que no sobrevivieron (809) que los que sí lo hicieron (500), pero no es un desbalance extremo.</p>
            
            <p>También es útil examinar la relación entre la variable objetivo y otras características importantes:</p>
            
<pre><code class="language-python"># Relación entre sexo y supervivencia
sns.countplot(x='sex', hue='survived', data=titanic_df)
plt.title('Supervivencia por Sexo')
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_1_1.png" alt="Supervivencia por sexo">
                <div class="caption">Supervivencia según el sexo del pasajero</div>
            </div>
            
            <p>El gráfico muestra claramente que el sexo fue un factor determinante en la supervivencia. Las mujeres tuvieron una tasa de supervivencia mucho mayor que los hombres, lo que refleja la política "mujeres y niños primero" durante el desastre.</p>
            
<pre><code class="language-python"># Relación entre clase y supervivencia
sns.countplot(x='pclass', hue='survived', data=titanic_df)
plt.title('Supervivencia por Clase')
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_1_2.png" alt="Supervivencia por clase">
                <div class="caption">Supervivencia según la clase del pasajero</div>
            </div>
            
            <p>También observamos una fuerte correlación entre la clase del pasajero y su probabilidad de supervivencia. Los pasajeros de primera clase tuvieron tasas de supervivencia significativamente mayores que los de tercera clase.</p>

            <p>Analicemos visualmente cómo las variables numéricas se relacionan con la supervivencia de pasajeros en el dataset del Titanic. Inicialmente, se utilizan diagramas de caja (boxplots) para comparar la distribución de cada variable numérica entre los pasajeros que sobrevivieron y los que no. Estos gráficos permiten identificar diferencias en medidas centrales (mediana), dispersión (rango intercuartílico) y valores atípicos entre ambos grupos. </p>

            <pre><code class="language-python">fig, axes = plt.subplots(1, 2, figsize=(8, 4))
axes = axes.flatten()
for i, col in enumerate(cols_numericas):
    sns.boxplot(data=titanic_df, x="survived", y=col, ax=axes[i])
    axes[i].set_title(col)
plt.tight_layout()
plt.show()</code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_2.png" alt="Numérica vs Supervivencia" width="70%">
                <div class="caption">Análisis de las variables numéricas frente a la variable survived</div>
            </div>

            <p>Enfoquémonos específicamente en la variable 'fare' (costo del boleto), empleando gráficos de densidad (KDE plots) para visualizar cómo se distribuyen los precios pagados según el estado de supervivencia. Esta visualización ayuda a identificar si existieron diferencias en las tarifas pagadas entre quienes sobrevivieron y quienes no, sugiriendo posibles relaciones entre el poder adquisitivo y las probabilidades de supervivencia. </p>

<pre><code class="language-python"># Gráfica con seaborn de la distribución de fare por survived
sns.kdeplot(data=titanic_df, x='fare', hue='survived', alpha=0.5, fill=True);
plt.ylabel("Costo del tiquete");</code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_3.png" alt="Fare vs Supervivencia" width="50%">
                <div class="caption">Distribución del costo del boleto según la variable survived</div>
            </div>

            <p>Analicemos ahora la relación entre variables categóricas y la supervivencia de pasajeros en el dataset del Titanic. En el primer fragmento, se utilizan mapas de calor (heatmaps) para visualizar la distribución conjunta de cada variable categórica con respecto a la supervivencia. Estos gráficos permiten identificar rápidamente patrones y posibles asociaciones entre categorías específicas y la probabilidad de sobrevivir.</p>

<pre><code class="language-python"># Crear gráficas de heatmap para ver la correlación entre las variables categóricas y la variable survived
fig, axes = plt.subplots(1, 3, figsize=(12, 4))
axes = axes.flatten()
for i, col in enumerate(cols_categoricas):
    sns.heatmap(pd.crosstab(titanic_df[col],
                           titanic_df["survived"]),
               annot=True, fmt="d",
               ax=axes[i])
    axes[i].set_title(col)
plt.tight_layout()</code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_4.png" alt="Categoricas vs Supervivencia" width="70%">
                <div class="caption">Correlación entre las variables categóricas y la variable survived</div>
            </div>

            <p>Complementemos el análisis visual con pruebas estadísticas de chi-cuadrado, que determinan si existe una asociación estadísticamente significativa entre cada variable categórica y la supervivencia. Los valores bajos de p (p-value) indicarían que la relación observada no se debe al azar, sino que existe una dependencia real entre las variables analizadas.</p> 

<pre><code class="language-python">from scipy import stats
resultados_chi2 = []
for col in cols_categoricas:
    # Calcular la prueba chi-cuadrado
    chi2, pval, dof, expected = stats.chi2_contingency(pd.crosstab(titanic_df[col],
                                                                  titanic_df["survived"]))
    # Guardar valores en pandas dataframe para concatenar con los resultados de otras variables
    df = pd.DataFrame({'variable': [col],
                       'chi2': [chi2],
                       'pval': [pval]})
    resultados_chi2.append(df)
df_chi2 = pd.concat(resultados_chi2, ignore_index=True)
df_chi2 </code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_4_1.png" alt="resultado chi-cuadrado" width="30%">
                <div class="caption">Resultados de la prueba chi-cuadrado</div>
            </div>
        </div>

        <div class="content-section">
            <h3 id="etapa-6-feature-engineering">Etapa 6: Feature Engineering</h3>

            <p>Antes de entrenar nuestros modelos, necesitamos preparar adecuadamente nuestras características mediante técnicas de preprocesamiento:</p>
            
<pre><code class="language-python">from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

# Definir columnas para diferentes tipos de transformaciones
cols_numericas = ["age", "fare", "sibsp", "parch"]
cols_categoricas = ["sex", "embarked"]
cols_categoricas_ord = ["pclass"]

# Pipeline para variables numéricas
numeric_pipe = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
])

# Pipeline para variables categóricas nominales
categorical_pipe = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder())])

# Pipeline para variables categóricas ordinales
categorical_ord_pipe = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OrdinalEncoder())])

# Combinar todos los pipelines en un preprocesador
preprocessor = ColumnTransformer(
    transformers=[
        ('numericas', numeric_pipe, cols_numericas),
        ('categoricas', categorical_pipe, cols_categoricas),
        ('categoricas ordinales', categorical_ord_pipe, cols_categoricas_ord)
    ])</code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_preprocessor.png" alt="Pipeline de Preprocesamiento" width="70%">
                <div class="caption">Pipeline de Preprocesamiento</div>
            </div>
            
            <p>Este enfoque de pipelines nos permite:</p>
            <ul>
                <li>Manejar valores faltantes utilizando diferentes estrategias según el tipo de variable</li>
                <li>Aplicar codificación one-hot para variables categóricas nominales</li>
                <li>Aplicar codificación ordinal para variables categóricas ordinales</li>
                <li>Asegurar que el preprocesamiento se aplique de manera consistente tanto en los datos de entrenamiento como en los de prueba</li>
            </ul>

            <h3 id="etapa-7-division">Etapa 7: División de Datos y Entrenamiento Inicial</h3>

            <p>Ahora dividimos nuestros datos en conjuntos de entrenamiento y prueba, y preparamos nuestra variable objetivo:</p>
            
<pre><code class="language-python">from sklearn.model_selection import train_test_split

# Separar características y variable objetivo
X_features = titanic_df.drop('survived', axis='columns')
y_target = titanic_df['survived']

# Dividir en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(
    X_features,
    y_target,
    test_size=0.2,
    stratify=y_target,  # Mantener la misma proporción de clases
    random_state=42
)

print(f"Tamaño de conjunto de entrenamiento: {X_train.shape[0]} ejemplos")
print(f"Tamaño de conjunto de prueba: {X_test.shape[0]} ejemplos")</code></pre>
            
<pre class="output"><code class="language-shell">Tamaño de conjunto de entrenamiento: 1047 ejemplos
Tamaño de conjunto de prueba: 262 ejemplos</code></pre>

            <h3 id="etapa-8-entrenamiento">Etapa 8: Entrenamiento y Evaluación de Múltiples Modelos</h3>

            <p>Vamos a entrenar y evaluar varios modelos de clasificación para comparar su rendimiento:</p>
            
<pre><code class="language-python">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB

# Función para resumir métricas de clasificación
def summarize_classification(y_test, y_pred):
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    return {
        'accuracy': acc,
        'precision': prec,
        'recall': recall,
        'f1': f1
    }

# Función para construir y evaluar un modelo
def build_model(classifier_fn, X_train, X_test, y_train, y_test):
    # Crear el pipeline con el preprocesamiento y el modelo
    pipe = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("model", classifier_fn)
    ])
    
    # Entrenar el modelo
    pipe.fit(X_train, y_train)
    
    # Predecir en train y test
    y_pred_train = pipe.predict(X_train)
    y_pred_test = pipe.predict(X_test)
    
    # Calcular métricas
    train_metrics = summarize_classification(y_train, y_pred_train)
    test_metrics = summarize_classification(y_test, y_pred_test)
    
    return {
        'pipeline': pipe,
        'train_metrics': train_metrics,
        'test_metrics': test_metrics
    }

# Diccionario para almacenar los resultados
results = {}

# Entrenar varios modelos
print("Entrenando modelos...")

# 1. Regresión Logística
results['logistic'] = build_model(
    LogisticRegression(solver='liblinear', max_iter=1000),
    X_train, X_test, y_train, y_test
)

# 2. Árbol de Decisión
results['decision_tree'] = build_model(
    DecisionTreeClassifier(random_state=42),
    X_train, X_test, y_train, y_test
)

# 3. Análisis Discriminante Lineal
results['lda'] = build_model(
    LinearDiscriminantAnalysis(),
    X_train, X_test, y_train, y_test
)

# 4. Naive Bayes
results['naive_bayes'] = build_model(
    GaussianNB(),
    X_train, X_test, y_train, y_test
)

# Comparar resultados (métricas F1)
for name, result in results.items():
    print(f"{name.ljust(15)}: Train F1 = {result['train_metrics']['f1']:.4f}, Test F1 = {result['test_metrics']['f1']:.4f}")</code></pre>
            
<pre class="output"><code class="language-shell">Entrenando modelos...
logistic       : Train F1 = 0.7681, Test F1 = 0.6842
decision_tree  : Train F1 = 0.7785, Test F1 = 0.6763
lda            : Train F1 = 0.7621, Test F1 = 0.6909
naive_bayes    : Train F1 = 0.7459, Test F1 = 0.6607</code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_models.png" alt="F1 score de los modelos" width="70%">
                <div class="caption">Comparación de Modelos usando F1 score</div>
            </div>

        </div>

        <div class="content-section">
            <h3 id="etapa-9-validacion">Etapa 9: Validación Cruzada para Selección de Modelos</h3>

            <p>Para obtener una estimación más robusta del rendimiento de nuestros modelos, utilizamos validación cruzada:</p>
            
<pre><code class="language-python">from sklearn.model_selection import cross_val_score

# Definir modelos a evaluar
models = [
    ('Logistic', LogisticRegression(solver='liblinear')),
    ('Decision Tree', DecisionTreeClassifier()),
    ('LDA', LinearDiscriminantAnalysis()),
    ('Naive Bayes', GaussianNB())
]

results = []
names = []
# Evaluar cada modelo con validación cruzada
for name, model in models:
    # Crear pipeline completo
    model_pipe = Pipeline(steps=[
        ("preprocessor", preprocessor),
        ("model", model)
    ])
    
    # Realizar validación cruzada
    cv_scores = cross_val_score(
        model_pipe, 
        X_train, y_train, 
        cv=10,  # 10-fold cross-validation
        scoring='f1'
    )

    results.append(cv_scores)
    names.append(name)
    
    print(f"{name}: F1 = {cv_scores.mean():.4f} (±{cv_scores.std():.4f})")</code></pre>
            
<pre class="output"><code class="language-shell">Logistic: F1 = 0.7091 (±0.0581)
Decision Tree: F1 = 0.7008 (±0.0379)
LDA: F1 = 0.7121 (±0.0553)</code></pre>

            <p>La validación cruzada nos muestra que los modelos LDA y Logistic Regression tienen el mejor rendimiento promedio, con puntajes F1 de 0.7121 y 0.7091 respectivamente.</p>

<pre><code class="language-python">plt.figure(figsize = (8,4))
result_df = pd.DataFrame(results, index=names).T
result_df.boxplot()
plt.title("Resultados de Cross Validation");

# Visualización de resultados de cada fold
plt.figure(figsize=(8, 4))
sns.lineplot(data=result_df)
plt.title("Resultados de cada Kfold")
plt.show()</code></pre>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_5.png" alt="Resultados de validación cruzada">
                <div class="caption">Resultados de validación cruzada para diferentes modelos</div>
            </div>

            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_6.png" alt="Resultados de cada K fold">
                <div class="caption">Resultados de validación cruzada para diferentes modelos</div>
            </div>

            <h3 id="etapa-10-optimizacion">Etapa 10: Optimización de Hiperparámetros</h3>

            <p>Ahora, optimizaremos los hiperparámetros de nuestros mejores modelos para mejorar aún más su rendimiento:</p>
            
<pre><code class="language-python">from sklearn.model_selection import GridSearchCV

# Optimización para Decision Tree
tree_params = {
    'model__max_depth': [4, 5, 7, 9, 10],
    'model__max_features': [2, 3, 4, 5, 6, 7, 8, 9],
    'model__criterion': ['gini', 'entropy'],
}

tree_pipe = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", DecisionTreeClassifier(random_state=42))
])

tree_search = GridSearchCV(
    tree_pipe,
    tree_params,
    cv=3,
    scoring='f1',
    return_train_score=True
)

tree_search.fit(X_train, y_train)

print("Mejores parámetros para Decision Tree:")
print(tree_search.best_params_)
print(f"Mejor puntaje F1: {tree_search.best_score_:.4f}")</code></pre>
            
<pre class="output"><code class="language-shell">Mejores parámetros para Decision Tree:
{'model__criterion': 'gini', 'model__max_depth': 9, 'model__max_features': 3}
Mejor puntaje F1: 0.7241</code></pre>
            
<pre><code class="language-python"># Optimización para Logistic Regression
log_params = {
    'model__C': [0.1, 0.4, 0.8, 1, 2, 5],
    'model__penalty': ['l1', 'l2'],
}

log_pipe = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", LogisticRegression(solver='liblinear'))
])

log_search = GridSearchCV(
    log_pipe,
    log_params,
    cv=3,
    scoring='f1',
    return_train_score=True
)

log_search.fit(X_train, y_train)

print("\nMejores parámetros para Logistic Regression:")
print(log_search.best_params_)
print(f"Mejor puntaje F1: {log_search.best_score_:.4f}")</code></pre>
            
<pre class="output"><code class="language-shell">Mejores parámetros para Logistic Regression:
{'model__C': 5, 'model__penalty': 'l1'}
Mejor puntaje F1: 0.7252</code></pre>

            <h3 id="etapa-11-evaluacion">Etapa 11: Evaluación Final del Modelo</h3>

            <p>Tras la optimización de hiperparámetros, vamos a evaluar exhaustivamente el rendimiento de nuestro Decision Tree con la configuración óptima:</p>
            
<pre><code class="language-python">from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

# Crear el modelo optimizado de Decision Tree con los mejores hiperparámetros
modelo = DecisionTreeClassifier(criterion='gini',
                              max_depth=9,
                              max_features=3,
                              random_state=42)

# Pipeline completo
decision_tree_pipe = Pipeline(steps=[("preprocessor", preprocessor),
                                   ("model", modelo)])

# Entrenar el modelo final
decision_tree_model = decision_tree_pipe.fit(X_train, y_train)

# Predecir en el conjunto de prueba
y_pred = decision_tree_model.predict(X_test)

# Generar reporte de clasificación
print("Reporte de Clasificación - Decision Tree:")
print(classification_report(y_test, y_pred))</code></pre>
            
<pre class="output"><code class="language-shell">Reporte de Clasificación - Decision Tree:
              precision    recall  f1-score   support

       False       0.77      0.94      0.85       162
        True       0.86      0.55      0.67       100

    accuracy                           0.79       262
   macro avg       0.82      0.75      0.76       262
weighted avg       0.81      0.79      0.78       262</code></pre>
            
            <p>Visualizamos la matriz de confusión para entender mejor los aciertos y errores del modelo:</p>
            
<pre><code class="language-python"># Visualizar matriz de confusión
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[False, True])
disp.plot(cmap='Blues')
plt.title('Matriz de Confusión - Decision Tree')
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_7.png" alt="Matriz de confusión del Decision Tree">
                <div class="caption">Matriz de confusión del modelo Decision Tree en el conjunto de prueba</div>
            </div>
            
            <p>Analizando el reporte de clasificación y la matriz de confusión, podemos observar:</p>
            
            <ul>
                <li><strong>Exactitud (Accuracy):</strong> 79%, lo que indica que el modelo clasifica correctamente aproximadamente 4 de cada 5 pasajeros.</li>
                <li><strong>Clase No Sobrevive (False):</strong> Alta sensibilidad (94%) pero precisión más baja (77%), lo que significa que el modelo es muy bueno identificando a los que no sobrevivieron, pero tiende a clasificar incorrectamente algunos sobrevivientes como no sobrevivientes.</li>
                <li><strong>Clase Sobrevive (True):</strong> Alta precisión (86%) pero sensibilidad más baja (55%), lo que indica que cuando el modelo predice que alguien sobrevive, generalmente acierta, pero tiende a perder casi la mitad de los casos de sobrevivientes reales.</li>
            </ul>
            
            <p>Este patrón de rendimiento es interesante: el modelo es conservador al predecir supervivencia, lo que resulta en menos falsos positivos pero más falsos negativos.</p>

        </div>

        <div class="content-section">
            <h3 id="etapa-12-interpretacion">Etapa 12: Interpretación del Modelo</h3>
            
            <p>Una ventaja clave de los árboles de decisión es su interpretabilidad. Vamos a examinar qué características son más importantes para nuestro modelo:</p>
            
<pre><code class="language-python"># Extraer y visualizar la importancia de las características
dfFeatures = pd.DataFrame({'Features': decision_tree_model['preprocessor'].get_feature_names_out(),
                          'Importances': decision_tree_model['model'].feature_importances_})

# Ordenar por importancia
dfFeatures = dfFeatures.sort_values(by='Importances', ascending=False)

# Mostrar las características más importantes
print("Características más importantes:")
print(dfFeatures)</code></pre>
            
<pre class="output"><code class="language-shell">Características más importantes:
                        Features  Importances
5          categoricas__sex_male     0.454508
1                numericas__fare     0.187830
0                 numericas__age     0.135766
2               numericas__sibsp     0.063084
3               numericas__parch     0.060102
9  categoricas ordinales__pclass     0.057476
6        categoricas__embarked_C     0.026747
8        categoricas__embarked_S     0.011760
7        categoricas__embarked_Q     0.002729
4        categoricas__sex_female     0.000000</code></pre>
            
            <p>Visualizamos estas importancias para facilitar su interpretación:</p>
            
<pre><code class="language-python"># Visualizar importancia de características
plt.figure(figsize=(10, 6))
sns.barplot(x='Importances', y='Features', data=dfFeatures)
plt.title('Importancia de Características - Decision Tree')
plt.tight_layout()
plt.show()</code></pre>
            
            <div class="img-container">
                <img src="https://github.com/AntonioEscamilla/images-in-readMe/raw/master/Curso%20Python/titanic_8.png" alt="Importancia de características en Decision Tree" width="70%">
                <div class="caption">Importancia relativa de las características en el modelo Decision Tree</div>
            </div>
            
            <h3>Análisis de la Importancia de Características</h3>
            
            <p>El análisis de importancia revela insights valiosos sobre los factores que determinaron la supervivencia en el desastre del Titanic:</p>
            
            <ul>
                <li><strong>Sexo (sex_male):</strong> Con una importancia del 45.5%, esta es por mucho la característica más influyente. Confirma históricamente la política de "mujeres y niños primero" implementada durante la evacuación.</li>
                <li><strong>Tarifa pagada (fare):</strong> Segunda característica más importante (18.8%), sugiriendo que el costo del boleto, que refleja la clase socioeconómica, tuvo un impacto significativo en las probabilidades de supervivencia.</li>
                <li><strong>Edad (age):</strong> Con una importancia del 13.6%, confirma que la edad fue un factor relevante en la supervivencia, probablemente favoreciendo a los niños durante la evacuación.</li>
                <li><strong>Relaciones familiares (sibsp y parch):</strong> Con una importancia combinada del 12.3%, indica que viajar con familia (hermanos/cónyuges o padres/hijos) afectó las probabilidades de supervivencia.</li>
                <li><strong>Clase del pasajero (pclass):</strong> Con un 5.7% de importancia, tuvo un impacto moderado. Es interesante notar que parte de su efecto ya está capturado en la variable 'fare'.</li>
                <li><strong>Puerto de embarque (embarked):</strong> Los puertos de embarque tienen una influencia menor (4.1% combinado).</li>
            </ul>
            
            <p>En base a estos resultados, podríamos probar un modelo simplificado que utilice solo las características más importantes. Esto podría mejorar la generalización del modelo y hacerlo más eficiente.</p>
            
            <div class="note">
                En los árboles de decisión, la importancia de las características se calcula según cuánto mejora cada característica la pureza de los nodos (medida por el índice Gini o la entropía). Características con mayor importancia contribuyen más a las decisiones críticas del árbol.
            </div>
            
            <h3>Modelo Simplificado con Características Importantes</h3>
            
            <p>Vamos a probar si podemos obtener un rendimiento similar utilizando solo las características más importantes:</p>
            
<pre><code class="language-python"># Utilizar solo las características principales: sexo, tarifa, edad y clase
X_train_reduced = X_train[['sex', 'fare', 'age', 'pclass']]
X_test_reduced = X_test[['sex', 'fare', 'age', 'pclass']]

# Actualizar las definiciones de columnas
cols_numericas = ["age", "fare"]
cols_categoricas = ["sex"]
cols_categoricas_ord = ["pclass"]

# Recrear el preprocesador
preprocessor_reduced = ColumnTransformer(
    transformers=[
        ('numericas', numeric_pipe, cols_numericas),
        ('categoricas', categorical_pipe, cols_categoricas),
        ('categoricas ordinales', categorical_ord_pipe, cols_categoricas_ord)
    ])

# Pipeline con modelo simplificado
simplified_pipe = Pipeline(steps=[
    ("preprocessor", preprocessor_reduced),
    ("model", DecisionTreeClassifier(criterion='gini', max_depth=9, max_features=3, random_state=42))
])

# Entrenar y evaluar
simplified_pipe.fit(X_train_reduced, y_train)
y_pred_simplified = simplified_pipe.predict(X_test_reduced)
print("Reporte del modelo simplificado:")
print(classification_report(y_test, y_pred_simplified))</code></pre>
            
<pre class="output"><code class="language-shell">Reporte del modelo simplificado:
              precision    recall  f1-score   support

       False       0.82      0.90      0.86       162
        True       0.81      0.67      0.73       100

    accuracy                           0.81       262
   macro avg       0.81      0.79      0.79       262
weighted avg       0.81      0.81      0.81       262</code></pre>
            
            <p>¡Notable! El modelo simplificado no solo mantiene el rendimiento, sino que incluso lo mejora ligeramente. Esto demuestra un principio importante en machine learning: a veces menos es más. Un modelo más simple puede generalizar mejor, evitar el sobreajuste y ser más fácil de interpretar y mantener.</p>
        </div>

        <div class="content-section">
            <h3 id="etapa-13-preparacion">Etapa 13: Preparación para Despliegue</h3>
            
            <p>Una vez finalizado el desarrollo y la evaluación del modelo, el último paso es prepararlo para su despliegue en producción. Esto implica serializar (guardar) el modelo para poder utilizarlo posteriormente sin necesidad de reentrenarlo:</p>
            
<pre><code class="language-python">from joblib import dump, load

# Entrenar el modelo final con todos los datos disponibles
final_pipe.fit(X_features, y_target)

# Guardar el modelo entrenado
dump(final_pipe, 'titanic_survival_model.joblib')
print("Modelo guardado correctamente.")

# Ejemplo de cómo cargar y utilizar el modelo guardado
loaded_model = load('titanic_survival_model.joblib')

# Crear un ejemplo para predecir
example = pd.DataFrame({
    'pclass': [1],
    'sex': ['female'],
    'age': [29.0],
    'sibsp': [0],
    'parch': [0],
    'fare': [211.34],
    'embarked': ['S']
})

# Realizar la predicción
prediction = loaded_model.predict(example)
proba = loaded_model.predict_proba(example)

print(f"Predicción: {'Sobrevive' if prediction[0] else 'No sobrevive'}")
print(f"Probabilidad de supervivencia: {proba[0][1]:.2f}")</code></pre>
            
<pre class="output"><code class="language-shell">Modelo guardado correctamente.
Predicción: Sobrevive
Probabilidad de supervivencia: 0.93</code></pre>
            
            <h3>Conclusiones del Proyecto</h3>
            
            <p>A lo largo de este workflow hemos seguido todos los pasos esenciales de un proyecto de clasificación:</p>
            
            <ol>
                <li><strong>Preparación y exploración de datos</strong>: Hemos comprendido las características del conjunto de datos, tratado los valores faltantes y convertido las variables a los tipos adecuados.</li>
                <li><strong>Análisis exploratorio</strong>: Visualizamos las relaciones entre nuestras variables para entender mejor el problema.</li>
                <li><strong>Preprocesamiento</strong>: Aplicamos técnicas de imputación y codificación para preparar nuestros datos para los algoritmos de machine learning.</li>
                <li><strong>Selección de modelos</strong>: Probamos diferentes algoritmos y utilizamos validación cruzada para comparar su rendimiento.</li>
                <li><strong>Optimización de hiperparámetros</strong>: Mejoramos el rendimiento de nuestros modelos mediante la búsqueda de los mejores hiperparámetros.</li>
                <li><strong>Evaluación final</strong>: Utilizamos el conjunto de prueba para obtener una estimación insesgada del rendimiento de nuestro modelo.</li>
                <li><strong>Interpretación</strong>: Analizamos la importancia de las características para entender mejor el problema.</li>
                <li><strong>Despliegue</strong>: Preparamos el modelo para su uso en producción.</li>
            </ol>
            
            <p>El modelo final basado en regresión logística alcanzó una precisión del 77% en el conjunto de prueba, con un puntaje F1 de 0.77. Las características más importantes para predecir la supervivencia fueron el sexo, la edad, la tarifa y la clase del pasajero.</p>
            
            <p>Este enfoque estructurado puede aplicarse a cualquier problema de clasificación, adaptando las técnicas específicas según la naturaleza de los datos y los requisitos del problema.</p>
        </div>

        <div class="content-section">
            <h2 id="material-practica">Material de Práctica</h2>

            <p>Para consolidar los conceptos aprendidos en este capítulo, te invitamos a realizar los siguientes ejercicios prácticos:</p>

            <ul class="resources-list">
                <li><strong><a href="https://colab.research.google.com/drive/1mPWz5i9LYEcPlhpx7r9dfGbGGMvo2RSu" target="_blank">Construcción de un proyecto de clasificación completo</a></strong> - Notebook con el flujo de trabajo completo presentado en este capítulo.</li>
            </ul>
            
            <div class="tip">
                <strong>Ejercicio práctico:</strong> Intenta replicar el flujo de trabajo presentado en este capítulo con un dataset diferente, como el dataset de Digits o Iris disponibles en scikit-learn. Compara el rendimiento de diferentes modelos y analiza qué características son más importantes en cada caso.
            </div>

            <h2 id="referencias">Referencias</h2>

            <p>Para profundizar en los conceptos de clasificación y técnicas relacionadas, recomendamos consultar estos recursos:</p>

            <ul class="resources-list">
                <li><strong><a href="https://scikit-learn.org/stable/supervised_learning.html" target="_blank">Documentación oficial de modelos de aprendizaje supervisado en scikit-learn</a></strong> - Referencia completa sobre implementación de modelos supervisados en Python.</li>
                <li><strong><a href="https://www.kaggle.com/datasets/marshalpatel3558/diabetes-prediction-dataset-legit-dataset" target="_blank">Competencia de Kaggle: Diabetes Prediction</a></strong> - Competencia popular para practicar técnicas avanzadas de clasificación.</li>
                <li><strong><a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py" target="_blank">Comparación de clasificadores en scikit-learn</a></strong> - Ejemplo de comparación de diferentes modelos de clasificación.</li>
            </ul>
        </div>
        
        <div class="content-section">
            <div class="feedback-section">
                <h3>¿Te ha resultado útil esta página?</h3>
                <div class="feedback-buttons">
                    <button class="btn feedback-btn feedback-yes">
                        <span class="feedback-icon">😊</span> Sí
                    </button>
                    <button class="btn feedback-btn feedback-no">
                        <span class="feedback-icon">🤔</span> No
                    </button>
                </div>
            </div>
     
            <!-- Nueva sección de navegación entre capítulos -->
            <div class="chapter-navigation">
                <a href="regression.html" class="nav-btn nav-prev">
                    <span class="nav-icon">◀</span> Capítulo Anterior
                </a>
                <a href="clustering.html" class="nav-btn nav-next">
                    Capítulo Siguiente <span class="nav-icon">▶</span>
                </a>
            </div>
        </div>
     
        <div class="footer">
            <p>© 2025 Python para Ciencia de Datos - Ph.D. Antonio Escamilla P.</p>
     
            <div class="license-icons">
                <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" target="_blank" class="license-link" title="Creative Commons BY-NC-ND 4.0">
                    <!-- Ícono CC -->
                    <span class="icon-tooltip" data-tooltip="Creative Commons">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <text x="12" y="14" font-family="Arial, sans-serif" font-size="8" font-weight="bold" text-anchor="middle" fill="var(--accent-green)">CC</text>
                        </svg>
                    </span>
                    
                    <!-- Ícono BY (Atribución) -->
                    <span class="icon-tooltip" data-tooltip="Atribución">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <circle cx="12" cy="8" r="2.5" fill="var(--accent-green)"/>
                            <path d="M8,16 L16,16 L16,13 C16,11.5 14,11 12,11 C10,11 8,11.5 8,13 L8,16 Z" fill="var(--accent-green)"/>
                        </svg>
                    </span>
                    
                    <!-- Ícono NC (No Comercial) -->
                    <span class="icon-tooltip" data-tooltip="No Comercial">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <text x="12" y="15" font-family="Arial, sans-serif" font-size="10" font-weight="bold" text-anchor="middle" fill="var(--accent-green)">$</text>
                            <line x1="6" y1="6" x2="18" y2="18" stroke="var(--accent-green)" stroke-width="2"/>
                        </svg>
                    </span>
                    
                    <!-- Ícono ND (Sin Derivadas) -->
                    <span class="icon-tooltip" data-tooltip="Sin Derivadas">
                        <svg class="license-icon" viewBox="0 0 24 24">
                            <circle cx="12" cy="12" r="11" fill="var(--primary-medium)"/>
                            <circle cx="12" cy="12" r="10" fill="none" stroke="var(--accent-green)" stroke-width="1"/>
                            <rect x="7" y="10" width="10" height="1.5" fill="var(--accent-green)"/>
                            <rect x="7" y="13" width="10" height="1.5" fill="var(--accent-green)"/>
                        </svg>
                    </span>
                </a>
            </div>
        </div>
    </div>
     
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // Aplicar resaltado a todos los bloques de código
            document.querySelectorAll('pre code').forEach(function(block) {
                hljs.highlightElement(block);
            });
            
            const hamburgerMenu = document.querySelector('.hamburger-menu');
            const hamburgerButton = document.querySelector('.hamburger-button');
            
            // Alternar menú al hacer clic en el botón
            hamburgerButton.addEventListener('click', function() {
                hamburgerMenu.classList.toggle('active');
            });
     
            // Cerrar menú al hacer clic en un enlace
            const menuLinks = document.querySelectorAll('.menu-content a');
            menuLinks.forEach(link => {
                link.addEventListener('click', function() {
                    hamburgerMenu.classList.remove('active');
                });
            });
     
            // Cerrar menú al hacer clic fuera de él
            document.addEventListener('click', function(event) {
                if (!hamburgerMenu.contains(event.target)) {
                    hamburgerMenu.classList.remove('active');
                }
            });
        });
    </script>
</body>
